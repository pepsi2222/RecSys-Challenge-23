[2023-06-17 20:46:50] INFO Log saved in /data2/home/xingmei/RecSys23/log/EDCN/recsys/2023-06-17-20-46-50.log.
[2023-06-17 20:46:50] INFO Global seed set to 2022
[2023-06-17 20:46:50] INFO Load dataset from cache.
[2023-06-17 20:46:52] INFO 
Dataset Info: 

=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
interaction information: 
field        f_1          f_2          f_3          f_4          f_5          f_6          f_8          f_9          f_10         f_11         f_12         f_13         f_14         f_15         f_16         f_17         f_18         f_19         f_20         f_21         f_22         f_23         f_24         f_25         f_26         f_30         f_31         f_32         f_33         f_34         f_35         f_36         f_37         f_38         f_39         f_40         f_41         f_42         f_43         f_44         f_45         f_46         f_47         f_48         f_49         f_50         f_51         f_52         f_53         f_54         f_55         f_56         f_57         f_58         f_59         f_60         f_61         f_62         f_63         f_64         f_65         f_66         f_67         f_68         f_69         f_70         f_71         f_72         f_73         f_74         f_75         f_76         f_77         f_78         f_79         is_installed 
type         float        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        float        token        token        token        token        token        token        token        token        token        token        token        token        token        token        float        float        token        token        token        token        float        float        float        float        float        float        float        token        token        token        token        token        token        token        token        token        float        
##           -            140          6            639          7            5235         7            8            4            25           27           332          20           5855         13           50           925          20           58           36           27           5            5            4            3            3            3            5            3            3            3            3            3            3            3            3            3            8883         -            22           24           12           28           28           21           35           1829         172          103          213          390          221          517          -            -            403          826          1397         408          -            -            -            -            -            -            -            5            12           9            5            32           9            5            14           8            -            
=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
Total Interactions: 3646825
=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
f_1=StandardScaler()
f_43=StandardScaler()
f_58=StandardScaler()
f_59=StandardScaler()
f_64=MinMaxScaler()
f_65=StandardScaler()
f_66=StandardScaler()
f_67=StandardScaler()
f_68=StandardScaler()
f_69=StandardScaler()
f_70=StandardScaler()
[2023-06-17 20:46:52] INFO 
Model Config: 

data:
	binarized_rating_thres=None
	fm_eval=False
	neg_count=0
	sampler=None
	shuffle=False
	split_mode=entry
	split_ratio=[3387880, 97972, 160973]
	fmeval=True
	low_rating_thres=None
eval:
	batch_size=4096
	cutoff=[5, 10, 20]
	val_metrics=['logloss', 'auc', 'accuracy', 'f1', 'precision', 'recall']
	val_n_epoch=1
	test_metrics=['logloss', 'auc', 'accuracy', 'f1', 'precision', 'recall']
	topk=100
	save_path=./saved/
	binarized_prob_thres=0.5
model:
	embed_dim=10
	item_bias=False
	bridge_type=hadamard_product
	temperature=1.0
	activation=relu
	num_layers=4
	dropout=0.5
	batch_norm=True
train:
	accelerator=gpu
	ann=None
	batch_size=512
	early_stop_mode=min
	early_stop_patience=10
	epochs=1000
	gpu=[4]
	grad_clip_norm=None
	init_method=xavier_normal
	item_batch_size=1024
	learner=adam
	learning_rate=0.001
	num_threads=10
	sampling_method=none
	sampler=uniform
	negative_count=0
	excluding_hist=False
	scheduler=None
	seed=2022
	weight_decay=0.0
	tensorboard_path=None
[2023-06-17 20:46:52] INFO save_dir:./saved/
[2023-06-17 20:46:52] INFO EDCN(
  (loss_fn): BCEWithLogitLoss()
  (embedding): Embeddings(
    num_features=75, embed_dim=10, reduction=mean
    (embeddings): ModuleDict(
      (f_61): Embedding(826, 10, padding_idx=0)
      (f_56): Embedding(221, 10, padding_idx=0)
      (f_74): Embedding(5, 10, padding_idx=0)
      (f_70): DenseEmbedding(
        embedding_dim=10, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=10, bias=False)
      )
      (f_36): Embedding(3, 10, padding_idx=0)
      (f_51): Embedding(1829, 10, padding_idx=0)
      (f_77): Embedding(5, 10, padding_idx=0)
      (f_12): Embedding(27, 10, padding_idx=0)
      (f_63): Embedding(408, 10, padding_idx=0)
      (f_47): Embedding(28, 10, padding_idx=0)
      (f_38): Embedding(3, 10, padding_idx=0)
      (f_4): Embedding(639, 10, padding_idx=0)
      (f_9): Embedding(8, 10, padding_idx=0)
      (f_15): Embedding(5855, 10, padding_idx=0)
      (f_34): Embedding(3, 10, padding_idx=0)
      (f_44): Embedding(22, 10, padding_idx=0)
      (f_6): Embedding(5235, 10, padding_idx=0)
      (f_22): Embedding(27, 10, padding_idx=0)
      (f_71): Embedding(5, 10, padding_idx=0)
      (f_23): Embedding(5, 10, padding_idx=0)
      (f_59): DenseEmbedding(
        embedding_dim=10, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=10, bias=False)
      )
      (f_33): Embedding(3, 10, padding_idx=0)
      (f_68): DenseEmbedding(
        embedding_dim=10, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=10, bias=False)
      )
      (f_40): Embedding(3, 10, padding_idx=0)
      (f_54): Embedding(213, 10, padding_idx=0)
      (f_21): Embedding(36, 10, padding_idx=0)
      (f_3): Embedding(6, 10, padding_idx=0)
      (f_43): DenseEmbedding(
        embedding_dim=10, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=10, bias=False)
      )
      (f_26): Embedding(3, 10, padding_idx=0)
      (f_5): Embedding(7, 10, padding_idx=0)
      (f_76): Embedding(9, 10, padding_idx=0)
      (f_67): DenseEmbedding(
        embedding_dim=10, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=10, bias=False)
      )
      (f_19): Embedding(20, 10, padding_idx=0)
      (f_16): Embedding(13, 10, padding_idx=0)
      (f_30): Embedding(3, 10, padding_idx=0)
      (f_35): Embedding(3, 10, padding_idx=0)
      (f_50): Embedding(35, 10, padding_idx=0)
      (f_79): Embedding(8, 10, padding_idx=0)
      (f_65): DenseEmbedding(
        embedding_dim=10, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=10, bias=False)
      )
      (f_1): DenseEmbedding(
        embedding_dim=10, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=10, bias=False)
      )
      (f_75): Embedding(32, 10, padding_idx=0)
      (f_57): Embedding(517, 10, padding_idx=0)
      (f_37): Embedding(3, 10, padding_idx=0)
      (f_13): Embedding(332, 10, padding_idx=0)
      (f_53): Embedding(103, 10, padding_idx=0)
      (f_60): Embedding(403, 10, padding_idx=0)
      (f_66): DenseEmbedding(
        embedding_dim=10, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=10, bias=False)
      )
      (f_20): Embedding(58, 10, padding_idx=0)
      (f_8): Embedding(7, 10, padding_idx=0)
      (f_25): Embedding(4, 10, padding_idx=0)
      (f_78): Embedding(14, 10, padding_idx=0)
      (f_55): Embedding(390, 10, padding_idx=0)
      (f_48): Embedding(28, 10, padding_idx=0)
      (f_14): Embedding(20, 10, padding_idx=0)
      (f_42): Embedding(8883, 10, padding_idx=0)
      (f_2): Embedding(140, 10, padding_idx=0)
      (f_32): Embedding(5, 10, padding_idx=0)
      (f_10): Embedding(4, 10, padding_idx=0)
      (f_39): Embedding(3, 10, padding_idx=0)
      (f_73): Embedding(9, 10, padding_idx=0)
      (f_31): Embedding(3, 10, padding_idx=0)
      (f_17): Embedding(50, 10, padding_idx=0)
      (f_69): DenseEmbedding(
        embedding_dim=10, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=10, bias=False)
      )
      (f_45): Embedding(24, 10, padding_idx=0)
      (f_41): Embedding(3, 10, padding_idx=0)
      (f_46): Embedding(12, 10, padding_idx=0)
      (f_49): Embedding(21, 10, padding_idx=0)
      (f_64): DenseEmbedding(
        embedding_dim=10, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=10, bias=False)
      )
      (f_11): Embedding(25, 10, padding_idx=0)
      (f_24): Embedding(5, 10, padding_idx=0)
      (f_52): Embedding(172, 10, padding_idx=0)
      (f_62): Embedding(1397, 10, padding_idx=0)
      (f_18): Embedding(925, 10, padding_idx=0)
      (f_58): DenseEmbedding(
        embedding_dim=10, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=10, bias=False)
      )
      (f_72): Embedding(12, 10, padding_idx=0)
    )
  )
  (cross): ModuleList(
    (0-3): 4 x CrossInteraction()
  )
  (mlp): ModuleList(
    (0-3): 4 x MLPModule(
      (model): Sequential(
        (0): Dropout(p=0.5, inplace=False)
        (1): Linear(in_features=750, out_features=750, bias=True)
        (2): BatchNorm1d(750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU()
      )
    )
  )
  (bridge): ModuleList(
    (0-3): 4 x BridgeLayer(
      bridge_type=hadamard_product
      (bridge): HStackLayer(
        (0): Sequential(
          (0): Linear(in_features=750, out_features=750, bias=True)
          (1): ReLU()
          (2): Linear(in_features=750, out_features=750, bias=False)
          (3): Softmax(dim=-1)
        )
        (1): Sequential(
          (0): Linear(in_features=750, out_features=750, bias=True)
          (1): ReLU()
          (2): Linear(in_features=750, out_features=750, bias=False)
          (3): Softmax(dim=-1)
        )
      )
    )
  )
  (regulation): ModuleList(
    (0-3): 4 x RegulationLayer(
      temperature=1.0
      (cross_bn): BatchNorm1d(750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (deep_bn): BatchNorm1d(750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (fc): Linear(in_features=2250, out_features=1, bias=True)
)
[2023-06-17 20:46:52] INFO GPU id [4] are selected.
[2023-06-17 20:50:06] INFO Training: Epoch=  0 [logloss=2.2356 accuracy=0.8176 f1=0.1954 precision=0.5655 recall=0.1183 auc=0.7846 train_loss_0=0.6998]
[2023-06-17 20:50:06] INFO Train time: 192.68183s. Valid time: 0.35063s. GPU RAM: 0.30/10.76 GB
[2023-06-17 20:50:06] INFO logloss improved. Best value: 2.2356
[2023-06-17 20:53:25] INFO Training: Epoch=  1 [logloss=0.7563 accuracy=0.8175 f1=0.1105 precision=0.6418 recall=0.0605 auc=0.8071 train_loss_0=0.3370]
[2023-06-17 20:53:25] INFO Train time: 198.85544s. Valid time: 0.60822s. GPU RAM: 0.34/10.76 GB
[2023-06-17 20:53:25] INFO logloss improved. Best value: 0.7563
[2023-06-17 20:56:50] INFO Training: Epoch=  2 [logloss=0.4264 accuracy=0.8218 f1=0.1909 precision=0.6407 recall=0.1123 auc=0.8187 train_loss_0=0.3037]
[2023-06-17 20:56:50] INFO Train time: 203.87564s. Valid time: 0.61008s. GPU RAM: 0.34/10.76 GB
[2023-06-17 20:56:50] INFO logloss improved. Best value: 0.4264
[2023-06-17 21:00:16] INFO Training: Epoch=  3 [logloss=0.3823 accuracy=0.8245 f1=0.2275 precision=0.6499 recall=0.1380 auc=0.8244 train_loss_0=0.2908]
[2023-06-17 21:00:16] INFO Train time: 205.44180s. Valid time: 0.58456s. GPU RAM: 0.34/10.76 GB
[2023-06-17 21:00:16] INFO logloss improved. Best value: 0.3823
[2023-06-17 21:03:40] INFO Training: Epoch=  4 [logloss=0.3830 accuracy=0.8268 f1=0.3715 precision=0.5803 recall=0.2733 auc=0.8271 train_loss_0=0.2827]
[2023-06-17 21:03:40] INFO Train time: 203.61222s. Valid time: 0.59643s. GPU RAM: 0.34/10.76 GB
[2023-06-17 21:07:17] INFO Training: Epoch=  5 [logloss=0.3822 accuracy=0.8246 f1=0.1992 precision=0.6883 recall=0.1165 auc=0.8276 train_loss_0=0.2739]
[2023-06-17 21:07:17] INFO Train time: 216.18617s. Valid time: 0.61241s. GPU RAM: 0.34/10.76 GB
[2023-06-17 21:07:17] INFO logloss improved. Best value: 0.3822
[2023-06-17 21:10:43] INFO Training: Epoch=  6 [logloss=0.3694 accuracy=0.8251 f1=0.1963 precision=0.7062 recall=0.1141 auc=0.8334 train_loss_0=0.2693]
[2023-06-17 21:10:43] INFO Train time: 205.41798s. Valid time: 0.56529s. GPU RAM: 0.34/10.76 GB
[2023-06-17 21:10:43] INFO logloss improved. Best value: 0.3694
[2023-06-17 21:14:09] INFO Training: Epoch=  7 [logloss=0.3910 accuracy=0.8263 f1=0.2880 precision=0.6212 recall=0.1876 auc=0.8281 train_loss_0=0.2645]
[2023-06-17 21:14:09] INFO Train time: 205.31106s. Valid time: 0.59396s. GPU RAM: 0.34/10.76 GB
[2023-06-17 21:17:34] INFO Training: Epoch=  8 [logloss=0.3812 accuracy=0.8245 f1=0.2299 precision=0.6473 recall=0.1399 auc=0.8204 train_loss_0=0.2641]
[2023-06-17 21:17:34] INFO Train time: 203.86430s. Valid time: 0.60365s. GPU RAM: 0.34/10.76 GB
[2023-06-17 21:20:59] INFO Training: Epoch=  9 [logloss=0.3883 accuracy=0.8236 f1=0.2695 precision=0.6022 recall=0.1737 auc=0.8137 train_loss_0=0.2613]
[2023-06-17 21:20:59] INFO Train time: 204.95697s. Valid time: 0.60242s. GPU RAM: 0.34/10.76 GB
[2023-06-17 21:24:26] INFO Training: Epoch= 10 [logloss=0.3891 accuracy=0.8230 f1=0.2247 precision=0.6276 recall=0.1369 auc=0.8139 train_loss_0=0.2578]
[2023-06-17 21:24:26] INFO Train time: 206.47838s. Valid time: 0.59843s. GPU RAM: 0.34/10.76 GB
[2023-06-17 21:27:51] INFO Training: Epoch= 11 [logloss=0.3842 accuracy=0.8249 f1=0.2682 precision=0.6191 recall=0.1713 auc=0.8162 train_loss_0=0.2579]
[2023-06-17 21:27:51] INFO Train time: 204.49752s. Valid time: 0.59324s. GPU RAM: 0.34/10.76 GB
[2023-06-17 21:31:38] INFO Training: Epoch= 12 [logloss=0.3868 accuracy=0.8235 f1=0.2368 precision=0.6250 recall=0.1462 auc=0.8073 train_loss_0=0.2537]
[2023-06-17 21:31:38] INFO Train time: 225.96589s. Valid time: 0.35146s. GPU RAM: 0.34/10.76 GB
[2023-06-17 21:34:59] INFO Training: Epoch= 13 [logloss=0.3933 accuracy=0.8227 f1=0.2288 precision=0.6190 recall=0.1404 auc=0.8158 train_loss_0=0.2521]
[2023-06-17 21:34:59] INFO Train time: 201.33247s. Valid time: 0.42308s. GPU RAM: 0.34/10.76 GB
[2023-06-17 21:38:19] INFO Training: Epoch= 14 [logloss=0.3862 accuracy=0.8233 f1=0.2514 precision=0.6111 recall=0.1584 auc=0.8110 train_loss_0=0.2515]
[2023-06-17 21:38:19] INFO Train time: 199.61221s. Valid time: 0.35310s. GPU RAM: 0.34/10.76 GB
[2023-06-17 21:41:37] INFO Training: Epoch= 15 [logloss=0.3824 accuracy=0.8245 f1=0.2805 precision=0.6056 recall=0.1827 auc=0.8175 train_loss_0=0.2507]
[2023-06-17 21:41:37] INFO Train time: 197.18905s. Valid time: 0.34832s. GPU RAM: 0.34/10.76 GB
[2023-06-17 21:44:56] INFO Training: Epoch= 16 [logloss=0.3819 accuracy=0.8239 f1=0.2965 precision=0.5903 recall=0.1981 auc=0.8164 train_loss_0=0.2485]
[2023-06-17 21:44:56] INFO Train time: 198.33601s. Valid time: 0.36476s. GPU RAM: 0.34/10.76 GB
[2023-06-17 21:44:56] INFO Early stopped. Since the metric logloss haven't been improved for 10 epochs.
[2023-06-17 21:44:56] INFO The best score of logloss is 0.3694 on epoch 6
[2023-06-17 21:44:56] INFO Best model checkpoint saved in ./saved/EDCN/recsys/2023-06-17-20-46-50.ckpt.
[2023-06-17 21:45:09] INFO Predictions saved in ./predictions/EDCN/2023-06-17-21-44-56is_installed.csv
