[2023-06-17 20:44:47] INFO Log saved in /data2/home/xingmei/RecSys23/log/DeepCrossing/recsys/2023-06-17-20-44-47.log.
[2023-06-17 20:44:47] INFO Global seed set to 2022
[2023-06-17 20:44:47] INFO Load dataset from cache.
[2023-06-17 20:44:48] INFO 
Dataset Info: 

=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
interaction information: 
field        f_1          f_2          f_3          f_4          f_5          f_6          f_8          f_9          f_10         f_11         f_12         f_13         f_14         f_15         f_16         f_17         f_18         f_19         f_20         f_21         f_22         f_23         f_24         f_25         f_26         f_30         f_31         f_32         f_33         f_34         f_35         f_36         f_37         f_38         f_39         f_40         f_41         f_42         f_43         f_44         f_45         f_46         f_47         f_48         f_49         f_50         f_51         f_52         f_53         f_54         f_55         f_56         f_57         f_58         f_59         f_60         f_61         f_62         f_63         f_64         f_65         f_66         f_67         f_68         f_69         f_70         f_71         f_72         f_73         f_74         f_75         f_76         f_77         f_78         f_79         is_installed 
type         float        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        float        token        token        token        token        token        token        token        token        token        token        token        token        token        token        float        float        token        token        token        token        float        float        float        float        float        float        float        token        token        token        token        token        token        token        token        token        float        
##           -            140          6            639          7            5235         7            8            4            25           27           332          20           5855         13           50           925          20           58           36           27           5            5            4            3            3            3            5            3            3            3            3            3            3            3            3            3            8883         -            22           24           12           28           28           21           35           1829         172          103          213          390          221          517          -            -            403          826          1397         408          -            -            -            -            -            -            -            5            12           9            5            32           9            5            14           8            -            
=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
Total Interactions: 3646825
=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
f_1=StandardScaler()
f_43=StandardScaler()
f_58=StandardScaler()
f_59=StandardScaler()
f_64=MinMaxScaler()
f_65=StandardScaler()
f_66=StandardScaler()
f_67=StandardScaler()
f_68=StandardScaler()
f_69=StandardScaler()
f_70=StandardScaler()
[2023-06-17 20:44:48] INFO 
Model Config: 

data:
	binarized_rating_thres=None
	fm_eval=False
	neg_count=0
	sampler=None
	shuffle=False
	split_mode=entry
	split_ratio=[3387880, 97972, 160973]
	fmeval=True
	low_rating_thres=None
eval:
	batch_size=4096
	cutoff=[5, 10, 20]
	val_metrics=['logloss', 'auc', 'accuracy', 'f1', 'precision', 'recall']
	val_n_epoch=1
	test_metrics=['logloss', 'auc', 'accuracy', 'f1', 'precision', 'recall']
	topk=100
	save_path=./saved/
	binarized_prob_thres=0.5
model:
	embed_dim=64
	item_bias=False
	hidden_dims=[256, 256, 256]
	activation=relu
	dropout=0.5
	batch_norm=True
	layer_norm=True
train:
	accelerator=gpu
	ann=None
	batch_size=512
	early_stop_mode=min
	early_stop_patience=10
	epochs=1000
	gpu=[1]
	grad_clip_norm=None
	init_method=xavier_normal
	item_batch_size=1024
	learner=adam
	learning_rate=0.001
	num_threads=10
	sampling_method=none
	sampler=uniform
	negative_count=0
	excluding_hist=False
	scheduler=None
	seed=2022
	weight_decay=1e-06
	tensorboard_path=None
[2023-06-17 20:44:48] INFO save_dir:./saved/
[2023-06-17 20:44:48] INFO DeepCrossing(
  (loss_fn): BCEWithLogitLoss()
  (dc): Sequential(
    (embedding): Embeddings(
      num_features=75, embed_dim=64, reduction=mean
      (embeddings): ModuleDict(
        (f_57): Embedding(517, 64, padding_idx=0)
        (f_74): Embedding(5, 64, padding_idx=0)
        (f_56): Embedding(221, 64, padding_idx=0)
        (f_5): Embedding(7, 64, padding_idx=0)
        (f_62): Embedding(1397, 64, padding_idx=0)
        (f_76): Embedding(9, 64, padding_idx=0)
        (f_13): Embedding(332, 64, padding_idx=0)
        (f_63): Embedding(408, 64, padding_idx=0)
        (f_69): DenseEmbedding(
          embedding_dim=64, bias=False, batch_norm=True
          (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (weight): Linear(in_features=1, out_features=64, bias=False)
        )
        (f_46): Embedding(12, 64, padding_idx=0)
        (f_4): Embedding(639, 64, padding_idx=0)
        (f_19): Embedding(20, 64, padding_idx=0)
        (f_49): Embedding(21, 64, padding_idx=0)
        (f_66): DenseEmbedding(
          embedding_dim=64, bias=False, batch_norm=True
          (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (weight): Linear(in_features=1, out_features=64, bias=False)
        )
        (f_51): Embedding(1829, 64, padding_idx=0)
        (f_73): Embedding(9, 64, padding_idx=0)
        (f_24): Embedding(5, 64, padding_idx=0)
        (f_20): Embedding(58, 64, padding_idx=0)
        (f_23): Embedding(5, 64, padding_idx=0)
        (f_43): DenseEmbedding(
          embedding_dim=64, bias=False, batch_norm=True
          (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (weight): Linear(in_features=1, out_features=64, bias=False)
        )
        (f_54): Embedding(213, 64, padding_idx=0)
        (f_3): Embedding(6, 64, padding_idx=0)
        (f_18): Embedding(925, 64, padding_idx=0)
        (f_78): Embedding(14, 64, padding_idx=0)
        (f_22): Embedding(27, 64, padding_idx=0)
        (f_14): Embedding(20, 64, padding_idx=0)
        (f_45): Embedding(24, 64, padding_idx=0)
        (f_59): DenseEmbedding(
          embedding_dim=64, bias=False, batch_norm=True
          (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (weight): Linear(in_features=1, out_features=64, bias=False)
        )
        (f_21): Embedding(36, 64, padding_idx=0)
        (f_8): Embedding(7, 64, padding_idx=0)
        (f_2): Embedding(140, 64, padding_idx=0)
        (f_39): Embedding(3, 64, padding_idx=0)
        (f_40): Embedding(3, 64, padding_idx=0)
        (f_79): Embedding(8, 64, padding_idx=0)
        (f_58): DenseEmbedding(
          embedding_dim=64, bias=False, batch_norm=True
          (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (weight): Linear(in_features=1, out_features=64, bias=False)
        )
        (f_11): Embedding(25, 64, padding_idx=0)
        (f_61): Embedding(826, 64, padding_idx=0)
        (f_65): DenseEmbedding(
          embedding_dim=64, bias=False, batch_norm=True
          (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (weight): Linear(in_features=1, out_features=64, bias=False)
        )
        (f_34): Embedding(3, 64, padding_idx=0)
        (f_64): DenseEmbedding(
          embedding_dim=64, bias=False, batch_norm=True
          (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (weight): Linear(in_features=1, out_features=64, bias=False)
        )
        (f_17): Embedding(50, 64, padding_idx=0)
        (f_26): Embedding(3, 64, padding_idx=0)
        (f_42): Embedding(8883, 64, padding_idx=0)
        (f_71): Embedding(5, 64, padding_idx=0)
        (f_47): Embedding(28, 64, padding_idx=0)
        (f_35): Embedding(3, 64, padding_idx=0)
        (f_36): Embedding(3, 64, padding_idx=0)
        (f_50): Embedding(35, 64, padding_idx=0)
        (f_1): DenseEmbedding(
          embedding_dim=64, bias=False, batch_norm=True
          (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (weight): Linear(in_features=1, out_features=64, bias=False)
        )
        (f_53): Embedding(103, 64, padding_idx=0)
        (f_25): Embedding(4, 64, padding_idx=0)
        (f_9): Embedding(8, 64, padding_idx=0)
        (f_77): Embedding(5, 64, padding_idx=0)
        (f_6): Embedding(5235, 64, padding_idx=0)
        (f_68): DenseEmbedding(
          embedding_dim=64, bias=False, batch_norm=True
          (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (weight): Linear(in_features=1, out_features=64, bias=False)
        )
        (f_38): Embedding(3, 64, padding_idx=0)
        (f_12): Embedding(27, 64, padding_idx=0)
        (f_16): Embedding(13, 64, padding_idx=0)
        (f_33): Embedding(3, 64, padding_idx=0)
        (f_75): Embedding(32, 64, padding_idx=0)
        (f_31): Embedding(3, 64, padding_idx=0)
        (f_72): Embedding(12, 64, padding_idx=0)
        (f_67): DenseEmbedding(
          embedding_dim=64, bias=False, batch_norm=True
          (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (weight): Linear(in_features=1, out_features=64, bias=False)
        )
        (f_10): Embedding(4, 64, padding_idx=0)
        (f_15): Embedding(5855, 64, padding_idx=0)
        (f_55): Embedding(390, 64, padding_idx=0)
        (f_41): Embedding(3, 64, padding_idx=0)
        (f_52): Embedding(172, 64, padding_idx=0)
        (f_60): Embedding(403, 64, padding_idx=0)
        (f_30): Embedding(3, 64, padding_idx=0)
        (f_32): Embedding(5, 64, padding_idx=0)
        (f_70): DenseEmbedding(
          embedding_dim=64, bias=False, batch_norm=True
          (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (weight): Linear(in_features=1, out_features=64, bias=False)
        )
        (f_37): Embedding(3, 64, padding_idx=0)
        (f_44): Embedding(22, 64, padding_idx=0)
        (f_48): Embedding(28, 64, padding_idx=0)
      )
    )
    (residuals): Sequential(
      (0): ResidualLayer(
        (module): MLPModule(
          (model): Sequential(
            (0): Dropout(p=0.0, inplace=False)
            (1): Linear(in_features=4800, out_features=256, bias=True)
            (2): ReLU()
            (3): Dropout(p=0.0, inplace=False)
            (4): Linear(in_features=256, out_features=4800, bias=True)
          )
        )
        (bn): BatchNorm1d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (1): ResidualLayer(
        (module): MLPModule(
          (model): Sequential(
            (0): Dropout(p=0.0, inplace=False)
            (1): Linear(in_features=4800, out_features=256, bias=True)
            (2): ReLU()
            (3): Dropout(p=0.0, inplace=False)
            (4): Linear(in_features=256, out_features=4800, bias=True)
          )
        )
        (bn): BatchNorm1d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (2): ResidualLayer(
        (module): MLPModule(
          (model): Sequential(
            (0): Dropout(p=0.0, inplace=False)
            (1): Linear(in_features=4800, out_features=256, bias=True)
            (2): ReLU()
            (3): Dropout(p=0.0, inplace=False)
            (4): Linear(in_features=256, out_features=4800, bias=True)
          )
        )
        (bn): BatchNorm1d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
  )
  (fc): Linear(in_features=4800, out_features=1, bias=True)
)
[2023-06-17 20:44:48] INFO GPU id [1] are selected.
[2023-06-17 20:47:32] INFO Training: Epoch=  0 [logloss=0.3860 accuracy=0.8204 f1=0.2736 precision=0.5648 recall=0.1807 auc=0.8127 train_loss_0=0.2727]
[2023-06-17 20:47:32] INFO Train time: 161.82801s. Valid time: 0.47742s. GPU RAM: 0.66/10.76 GB
[2023-06-17 20:47:32] INFO logloss improved. Best value: 0.3860
[2023-06-17 20:54:59] INFO Training: Epoch=  1 [logloss=0.3881 accuracy=0.8236 f1=0.1906 precision=0.6803 recall=0.1109 auc=0.8238 train_loss_0=0.2591]
[2023-06-17 20:54:59] INFO Train time: 445.32457s. Valid time: 1.66177s. GPU RAM: 0.66/10.76 GB
[2023-06-17 20:58:48] INFO Training: Epoch=  2 [logloss=0.3749 accuracy=0.8251 f1=0.2530 precision=0.6338 recall=0.1582 auc=0.8324 train_loss_0=0.2550]
[2023-06-17 20:58:48] INFO Train time: 228.76253s. Valid time: 0.44917s. GPU RAM: 0.66/10.76 GB
[2023-06-17 20:58:48] INFO logloss improved. Best value: 0.3749
[2023-06-17 21:01:32] INFO Training: Epoch=  3 [logloss=0.3826 accuracy=0.8253 f1=0.2433 precision=0.6465 recall=0.1499 auc=0.8249 train_loss_0=0.2519]
[2023-06-17 21:01:32] INFO Train time: 163.51952s. Valid time: 0.43884s. GPU RAM: 0.66/10.76 GB
[2023-06-17 21:04:17] INFO Training: Epoch=  4 [logloss=0.3771 accuracy=0.8245 f1=0.3050 precision=0.5915 recall=0.2055 auc=0.8297 train_loss_0=0.2497]
[2023-06-17 21:04:17] INFO Train time: 164.32788s. Valid time: 0.42142s. GPU RAM: 0.66/10.76 GB
[2023-06-17 21:07:00] INFO Training: Epoch=  5 [logloss=0.3770 accuracy=0.8267 f1=0.2989 precision=0.6185 recall=0.1972 auc=0.8230 train_loss_0=0.2480]
[2023-06-17 21:07:00] INFO Train time: 162.45975s. Valid time: 0.42221s. GPU RAM: 0.66/10.76 GB
[2023-06-17 21:09:07] INFO Training: Epoch=  6 [logloss=0.3876 accuracy=0.8247 f1=0.2492 precision=0.6310 recall=0.1554 auc=0.8276 train_loss_0=0.2463]
[2023-06-17 21:09:07] INFO Train time: 127.09409s. Valid time: 0.42331s. GPU RAM: 0.66/10.76 GB
[2023-06-17 21:11:54] INFO Training: Epoch=  7 [logloss=0.3883 accuracy=0.8228 f1=0.2917 precision=0.5817 recall=0.1948 auc=0.8160 train_loss_0=0.2448]
[2023-06-17 21:11:54] INFO Train time: 166.84311s. Valid time: 0.41637s. GPU RAM: 0.66/10.76 GB
[2023-06-17 21:14:36] INFO Training: Epoch=  8 [logloss=0.3745 accuracy=0.8227 f1=0.3289 precision=0.5658 recall=0.2319 auc=0.8255 train_loss_0=0.2432]
[2023-06-17 21:14:36] INFO Train time: 161.32756s. Valid time: 0.43610s. GPU RAM: 0.66/10.76 GB
[2023-06-17 21:14:36] INFO logloss improved. Best value: 0.3745
[2023-06-17 21:17:20] INFO Training: Epoch=  9 [logloss=0.3811 accuracy=0.8245 f1=0.3036 precision=0.5924 recall=0.2042 auc=0.8283 train_loss_0=0.2416]
[2023-06-17 21:17:20] INFO Train time: 163.04592s. Valid time: 0.42694s. GPU RAM: 0.67/10.76 GB
[2023-06-17 21:20:01] INFO Training: Epoch= 10 [logloss=0.3801 accuracy=0.8239 f1=0.3440 precision=0.5701 recall=0.2465 auc=0.8203 train_loss_0=0.2400]
[2023-06-17 21:20:01] INFO Train time: 161.02338s. Valid time: 0.43067s. GPU RAM: 0.67/10.76 GB
[2023-06-17 21:22:43] INFO Training: Epoch= 11 [logloss=0.3885 accuracy=0.8177 f1=0.3410 precision=0.5290 recall=0.2518 auc=0.8133 train_loss_0=0.2382]
[2023-06-17 21:22:43] INFO Train time: 161.70656s. Valid time: 0.42929s. GPU RAM: 0.67/10.76 GB
[2023-06-17 21:25:26] INFO Training: Epoch= 12 [logloss=0.3862 accuracy=0.8211 f1=0.3327 precision=0.5527 recall=0.2382 auc=0.8172 train_loss_0=0.2364]
[2023-06-17 21:25:26] INFO Train time: 161.76922s. Valid time: 0.42918s. GPU RAM: 0.67/10.76 GB
[2023-06-17 21:28:09] INFO Training: Epoch= 13 [logloss=0.3832 accuracy=0.8222 f1=0.3281 precision=0.5622 recall=0.2319 auc=0.8194 train_loss_0=0.2345]
[2023-06-17 21:28:09] INFO Train time: 162.99464s. Valid time: 0.42416s. GPU RAM: 0.67/10.76 GB
[2023-06-17 21:30:52] INFO Training: Epoch= 14 [logloss=0.3860 accuracy=0.8198 f1=0.3384 precision=0.5425 recall=0.2461 auc=0.8168 train_loss_0=0.2326]
[2023-06-17 21:30:52] INFO Train time: 162.60673s. Valid time: 0.43647s. GPU RAM: 0.67/10.76 GB
[2023-06-17 21:33:36] INFO Training: Epoch= 15 [logloss=0.3899 accuracy=0.8222 f1=0.3369 precision=0.5597 recall=0.2412 auc=0.8179 train_loss_0=0.2306]
[2023-06-17 21:33:36] INFO Train time: 163.65661s. Valid time: 0.42766s. GPU RAM: 0.67/10.76 GB
[2023-06-17 21:36:22] INFO Training: Epoch= 16 [logloss=0.3883 accuracy=0.8194 f1=0.3591 precision=0.5360 recall=0.2702 auc=0.8170 train_loss_0=0.2287]
[2023-06-17 21:36:22] INFO Train time: 165.73200s. Valid time: 0.41707s. GPU RAM: 0.67/10.76 GB
[2023-06-17 21:39:06] INFO Training: Epoch= 17 [logloss=0.3896 accuracy=0.8196 f1=0.3603 precision=0.5371 recall=0.2713 auc=0.8154 train_loss_0=0.2267]
[2023-06-17 21:39:06] INFO Train time: 163.26839s. Valid time: 0.42422s. GPU RAM: 0.67/10.76 GB
[2023-06-17 21:41:48] INFO Training: Epoch= 18 [logloss=0.3947 accuracy=0.8151 f1=0.3682 precision=0.5118 recall=0.2877 auc=0.8099 train_loss_0=0.2246]
[2023-06-17 21:41:48] INFO Train time: 161.58046s. Valid time: 0.41821s. GPU RAM: 0.67/10.76 GB
[2023-06-17 21:41:48] INFO Early stopped. Since the metric logloss haven't been improved for 10 epochs.
[2023-06-17 21:41:48] INFO The best score of logloss is 0.3745 on epoch 8
[2023-06-17 21:41:48] INFO Best model checkpoint saved in ./saved/DeepCrossing/recsys/2023-06-17-20-44-47.ckpt.
[2023-06-17 21:42:05] INFO Predictions saved in ./predictions/DeepCrossing/2023-06-17-21-41-48is_installed.csv
