[2023-06-19 11:08:56] INFO Log saved in /data2/home/xingmei/RecSys23/log/AITM/finetune/2023-06-19-11-08-56.log.
[2023-06-19 11:08:56] INFO Global seed set to 2022
[2023-06-19 11:08:56] INFO Load dataset from cache.
[2023-06-19 11:08:57] INFO 
Dataset Info: 

======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
interaction information: 
field        f_1          f_2          f_3          f_4          f_5          f_6          f_8          f_9          f_10         f_11         f_12         f_13         f_14         f_15         f_16         f_17         f_18         f_19         f_20         f_21         f_22         f_23         f_24         f_25         f_26         f_30         f_31         f_32         f_33         f_34         f_35         f_36         f_37         f_38         f_39         f_40         f_41         f_42         f_43         f_44         f_45         f_46         f_47         f_48         f_49         f_50         f_51         f_52         f_53         f_54         f_55         f_56         f_57         f_58         f_59         f_60         f_61         f_62         f_63         f_64         f_65         f_66         f_67         f_68         f_69         f_70         f_71         f_72         f_73         f_74         f_75         f_76         f_77         f_78         f_79         is_clicked   is_installed 
type         float        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        float        token        token        token        token        token        token        token        token        token        token        token        token        token        token        float        float        token        token        token        token        float        float        float        float        float        float        float        token        token        token        token        token        token        token        token        token        float        float        
##           -            136          6            631          7            4455         7            8            4            25           25           206          19           4277         11           42           543          20           56           35           25           5            5            4            3            3            3            5            3            3            3            3            3            3            3            3            3            6725         -            18           19           11           21           21           15           22           1725         133          85           172          306          182          415          -            -            232          584          1032         298          -            -            -            -            -            -            -            5            12           9            5            32           9            5            11           7            -            -            
======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
Total Interactions: 1045756
======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
f_1=StandardScaler()
f_43=StandardScaler()
f_58=StandardScaler()
f_59=StandardScaler()
f_64=MinMaxScaler()
f_65=StandardScaler()
f_66=StandardScaler()
f_67=StandardScaler()
f_68=StandardScaler()
f_69=StandardScaler()
f_70=StandardScaler()
[2023-06-19 11:08:57] INFO 
Model Config: 

data:
	binarized_rating_thres=None
	fm_eval=False
	neg_count=0
	sampler=None
	shuffle=False
	split_mode=entry
	split_ratio=[1016364, 29392, 0]
	fmeval=True
	low_rating_thres=None
eval:
	batch_size=4096
	cutoff=[5, 10, 20]
	val_metrics=['logloss', 'auc', 'accuracy', 'f1', 'precision', 'recall']
	val_n_epoch=1
	test_metrics=['logloss', 'auc', 'accuracy', 'f1', 'precision', 'recall']
	topk=100
	save_path=./saved/
	binarized_prob_thres=0.5
	main_task=is_installed
model:
	embed_dim=64
	item_bias=False
	tower_mlp_layer=[128, 64]
	tower_activation=relu
	tower_dropout=0
	tower_batch_norm=False
	alpha=0.6
train:
	accelerator=gpu
	ann=None
	batch_size=512
	early_stop_mode=min
	early_stop_patience=10
	epochs=1000
	gpu=[6]
	grad_clip_norm=None
	init_method=xavier_normal
	item_batch_size=1024
	learner=adam
	learning_rate=0.001
	num_threads=10
	sampling_method=none
	sampler=uniform
	negative_count=0
	excluding_hist=False
	scheduler=None
	seed=2022
	weight_decay=1e-05
	tensorboard_path=None
	weights=[1.0, 10.0]
[2023-06-19 11:08:57] INFO save_dir:./saved/
[2023-06-19 11:08:57] INFO AITM(
  (loss_fn): BCEWithLogitLoss()
  (embedding): Embeddings(
    num_features=75, embed_dim=64, reduction=mean
    (embeddings): ModuleDict(
      (f_74): Embedding(5, 64, padding_idx=0)
      (f_5): Embedding(7, 64, padding_idx=0)
      (f_65): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_22): Embedding(25, 64, padding_idx=0)
      (f_23): Embedding(5, 64, padding_idx=0)
      (f_43): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_2): Embedding(136, 64, padding_idx=0)
      (f_50): Embedding(22, 64, padding_idx=0)
      (f_36): Embedding(3, 64, padding_idx=0)
      (f_69): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_31): Embedding(3, 64, padding_idx=0)
      (f_9): Embedding(8, 64, padding_idx=0)
      (f_19): Embedding(20, 64, padding_idx=0)
      (f_40): Embedding(3, 64, padding_idx=0)
      (f_79): Embedding(7, 64, padding_idx=0)
      (f_78): Embedding(11, 64, padding_idx=0)
      (f_70): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_67): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_62): Embedding(1032, 64, padding_idx=0)
      (f_8): Embedding(7, 64, padding_idx=0)
      (f_60): Embedding(232, 64, padding_idx=0)
      (f_51): Embedding(1725, 64, padding_idx=0)
      (f_44): Embedding(18, 64, padding_idx=0)
      (f_59): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_72): Embedding(12, 64, padding_idx=0)
      (f_37): Embedding(3, 64, padding_idx=0)
      (f_73): Embedding(9, 64, padding_idx=0)
      (f_26): Embedding(3, 64, padding_idx=0)
      (f_35): Embedding(3, 64, padding_idx=0)
      (f_46): Embedding(11, 64, padding_idx=0)
      (f_32): Embedding(5, 64, padding_idx=0)
      (f_76): Embedding(9, 64, padding_idx=0)
      (f_56): Embedding(182, 64, padding_idx=0)
      (f_48): Embedding(21, 64, padding_idx=0)
      (f_12): Embedding(25, 64, padding_idx=0)
      (f_14): Embedding(19, 64, padding_idx=0)
      (f_54): Embedding(172, 64, padding_idx=0)
      (f_53): Embedding(85, 64, padding_idx=0)
      (f_33): Embedding(3, 64, padding_idx=0)
      (f_10): Embedding(4, 64, padding_idx=0)
      (f_64): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_66): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_71): Embedding(5, 64, padding_idx=0)
      (f_75): Embedding(32, 64, padding_idx=0)
      (f_38): Embedding(3, 64, padding_idx=0)
      (f_17): Embedding(42, 64, padding_idx=0)
      (f_1): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_18): Embedding(543, 64, padding_idx=0)
      (f_21): Embedding(35, 64, padding_idx=0)
      (f_39): Embedding(3, 64, padding_idx=0)
      (f_52): Embedding(133, 64, padding_idx=0)
      (f_58): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_47): Embedding(21, 64, padding_idx=0)
      (f_13): Embedding(206, 64, padding_idx=0)
      (f_45): Embedding(19, 64, padding_idx=0)
      (f_55): Embedding(306, 64, padding_idx=0)
      (f_49): Embedding(15, 64, padding_idx=0)
      (f_11): Embedding(25, 64, padding_idx=0)
      (f_57): Embedding(415, 64, padding_idx=0)
      (f_68): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_41): Embedding(3, 64, padding_idx=0)
      (f_24): Embedding(5, 64, padding_idx=0)
      (f_25): Embedding(4, 64, padding_idx=0)
      (f_34): Embedding(3, 64, padding_idx=0)
      (f_6): Embedding(4455, 64, padding_idx=0)
      (f_42): Embedding(6725, 64, padding_idx=0)
      (f_20): Embedding(56, 64, padding_idx=0)
      (f_4): Embedding(631, 64, padding_idx=0)
      (f_16): Embedding(11, 64, padding_idx=0)
      (f_30): Embedding(3, 64, padding_idx=0)
      (f_63): Embedding(298, 64, padding_idx=0)
      (f_61): Embedding(584, 64, padding_idx=0)
      (f_3): Embedding(6, 64, padding_idx=0)
      (f_77): Embedding(5, 64, padding_idx=0)
      (f_15): Embedding(4277, 64, padding_idx=0)
    )
  )
  (towers): ModuleDict(
    (is_clicked): MLPModule(
      (model): Sequential(
        (0): Dropout(p=0, inplace=False)
        (1): Linear(in_features=4800, out_features=128, bias=True)
        (2): ReLU()
        (3): Dropout(p=0, inplace=False)
        (4): Linear(in_features=128, out_features=64, bias=True)
        (5): ReLU()
      )
    )
    (is_installed): MLPModule(
      (model): Sequential(
        (0): Dropout(p=0, inplace=False)
        (1): Linear(in_features=4800, out_features=128, bias=True)
        (2): ReLU()
        (3): Dropout(p=0, inplace=False)
        (4): Linear(in_features=128, out_features=64, bias=True)
        (5): ReLU()
      )
    )
  )
  (att_layers): ModuleDict(
    (is_installed): AttentionLayer(
      (attn_layer): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
      )
    )
  )
  (info_layers): ModuleDict(
    (is_clicked): Sequential(
      (0): Linear(in_features=64, out_features=64, bias=True)
      (1): ReLU()
    )
  )
  (fc_layers): ModuleDict(
    (is_clicked): Linear(in_features=64, out_features=1, bias=True)
    (is_installed): Linear(in_features=64, out_features=1, bias=True)
  )
)
[2023-06-19 11:08:57] INFO GPU id [6] are selected.
[2023-06-19 11:10:46] INFO Training: Epoch=  0 [train_loss_0=0.2811 is_clicked logloss=0.8459 accuracy=0.3639 f1=0.5335 precision=0.3639 recall=0.9992 auc=0.5956 train_loss_0=1.7198 is_installed logloss=0.3792 accuracy=0.8250 f1=0.2352 precision=0.6661 recall=0.1430 auc=0.8251 train_loss_0=0.2807]
[2023-06-19 11:10:46] INFO Train time: 107.52572s. Valid time: 0.49138s. GPU RAM: 0.24/10.76 GB
[2023-06-19 11:10:46] INFO logloss improved. Best value: 0.3792
[2023-06-19 11:12:32] INFO Training: Epoch=  1 [train_loss_0=0.2660 is_clicked logloss=0.6900 accuracy=0.5917 f1=0.4478 precision=0.4412 recall=0.4550 auc=0.5972 train_loss_0=1.1094 is_installed logloss=0.3813 accuracy=0.8241 f1=0.2059 precision=0.6918 recall=0.1211 auc=0.8222 train_loss_0=0.2659]
[2023-06-19 11:12:32] INFO Train time: 105.71506s. Valid time: 0.46168s. GPU RAM: 0.24/10.76 GB
[2023-06-19 11:14:15] INFO Training: Epoch=  2 [train_loss_0=0.2620 is_clicked logloss=0.7057 accuracy=0.5819 f1=0.3935 precision=0.4171 recall=0.3727 auc=0.5938 train_loss_0=1.0343 is_installed logloss=0.3826 accuracy=0.8197 f1=0.3471 precision=0.5477 recall=0.2545 auc=0.8124 train_loss_0=0.2619]
[2023-06-19 11:14:15] INFO Train time: 101.92496s. Valid time: 0.46070s. GPU RAM: 0.24/10.76 GB
[2023-06-19 11:15:57] INFO Training: Epoch=  3 [train_loss_0=0.2588 is_clicked logloss=0.7101 accuracy=0.5740 f1=0.3803 precision=0.4043 recall=0.3593 auc=0.5824 train_loss_0=0.9853 is_installed logloss=0.3777 accuracy=0.8205 f1=0.3268 precision=0.5579 recall=0.2313 auc=0.8212 train_loss_0=0.2587]
[2023-06-19 11:15:57] INFO Train time: 102.22411s. Valid time: 0.43896s. GPU RAM: 0.24/10.76 GB
[2023-06-19 11:15:58] INFO logloss improved. Best value: 0.3777
[2023-06-19 11:17:38] INFO Training: Epoch=  4 [train_loss_0=0.2554 is_clicked logloss=0.7295 accuracy=0.5700 f1=0.4574 precision=0.4231 recall=0.4980 auc=0.5825 train_loss_0=0.9822 is_installed logloss=0.3894 accuracy=0.8223 f1=0.2860 precision=0.5900 recall=0.1891 auc=0.8051 train_loss_0=0.2553]
[2023-06-19 11:17:38] INFO Train time: 99.43598s. Valid time: 0.41329s. GPU RAM: 0.24/10.76 GB
[2023-06-19 11:19:17] INFO Training: Epoch=  5 [train_loss_0=0.2524 is_clicked logloss=0.7209 accuracy=0.5874 f1=0.4582 precision=0.4390 recall=0.4794 auc=0.6003 train_loss_0=1.0107 is_installed logloss=0.3926 accuracy=0.8211 f1=0.2153 precision=0.6253 recall=0.1302 auc=0.8211 train_loss_0=0.2523]
[2023-06-19 11:19:17] INFO Train time: 98.81633s. Valid time: 0.41580s. GPU RAM: 0.24/10.76 GB
[2023-06-19 11:20:54] INFO Training: Epoch=  6 [train_loss_0=0.2494 is_clicked logloss=0.7266 accuracy=0.5882 f1=0.4880 precision=0.4459 recall=0.5391 auc=0.6014 train_loss_0=1.0405 is_installed logloss=0.3941 accuracy=0.8198 f1=0.1952 precision=0.6196 recall=0.1159 auc=0.8130 train_loss_0=0.2493]
[2023-06-19 11:20:54] INFO Train time: 96.37623s. Valid time: 0.35458s. GPU RAM: 0.24/10.76 GB
[2023-06-19 11:22:30] INFO Training: Epoch=  7 [train_loss_0=0.2465 is_clicked logloss=0.7255 accuracy=0.5731 f1=0.4885 precision=0.4333 recall=0.5600 auc=0.6004 train_loss_0=1.0769 is_installed logloss=0.4143 accuracy=0.8209 f1=0.1717 precision=0.6722 recall=0.0986 auc=0.8108 train_loss_0=0.2463]
[2023-06-19 11:22:30] INFO Train time: 95.43955s. Valid time: 0.41831s. GPU RAM: 0.24/10.76 GB
[2023-06-19 11:24:06] INFO Training: Epoch=  8 [train_loss_0=0.2433 is_clicked logloss=0.8090 accuracy=0.5497 f1=0.5282 precision=0.4270 recall=0.6925 auc=0.5954 train_loss_0=1.1199 is_installed logloss=0.3954 accuracy=0.8187 f1=0.3273 precision=0.5444 recall=0.2341 auc=0.8048 train_loss_0=0.2432]
[2023-06-19 11:24:06] INFO Train time: 96.03005s. Valid time: 0.46482s. GPU RAM: 0.24/10.76 GB
[2023-06-19 11:25:39] INFO Training: Epoch=  9 [train_loss_0=0.2399 is_clicked logloss=0.8317 accuracy=0.5533 f1=0.5344 precision=0.4307 recall=0.7043 auc=0.6026 train_loss_0=1.1762 is_installed logloss=0.3879 accuracy=0.8216 f1=0.2913 precision=0.5802 recall=0.1948 auc=0.8207 train_loss_0=0.2398]
[2023-06-19 11:25:39] INFO Train time: 92.06773s. Valid time: 0.46873s. GPU RAM: 0.24/10.76 GB
[2023-06-19 11:27:09] INFO Training: Epoch= 10 [train_loss_0=0.2362 is_clicked logloss=0.8487 accuracy=0.5585 f1=0.5381 precision=0.4346 recall=0.7065 auc=0.6005 train_loss_0=1.2304 is_installed logloss=0.3883 accuracy=0.8180 f1=0.3281 precision=0.5397 recall=0.2361 auc=0.8121 train_loss_0=0.2361]
[2023-06-19 11:27:09] INFO Train time: 90.14767s. Valid time: 0.39983s. GPU RAM: 0.24/10.76 GB
[2023-06-19 11:28:43] INFO Training: Epoch= 11 [train_loss_0=0.2319 is_clicked logloss=0.8594 accuracy=0.5348 f1=0.5370 precision=0.4211 recall=0.7412 auc=0.5962 train_loss_0=1.3285 is_installed logloss=0.3979 accuracy=0.8207 f1=0.2675 precision=0.5831 recall=0.1738 auc=0.8090 train_loss_0=0.2317]
[2023-06-19 11:28:43] INFO Train time: 93.49443s. Valid time: 0.44794s. GPU RAM: 0.24/10.76 GB
[2023-06-19 11:30:15] INFO Training: Epoch= 12 [train_loss_0=0.2272 is_clicked logloss=0.8983 accuracy=0.5501 f1=0.5338 precision=0.4287 recall=0.7076 auc=0.5879 train_loss_0=1.4178 is_installed logloss=0.3956 accuracy=0.8196 f1=0.3059 precision=0.5569 recall=0.2111 auc=0.8134 train_loss_0=0.2270]
[2023-06-19 11:30:15] INFO Train time: 91.47080s. Valid time: 0.37373s. GPU RAM: 0.24/10.76 GB
[2023-06-19 11:31:45] INFO Training: Epoch= 13 [train_loss_0=0.2219 is_clicked logloss=0.9713 accuracy=0.5090 f1=0.5436 precision=0.4109 recall=0.8033 auc=0.5989 train_loss_0=1.5194 is_installed logloss=0.4097 accuracy=0.8205 f1=0.3006 precision=0.5669 recall=0.2047 auc=0.8066 train_loss_0=0.2217]
[2023-06-19 11:31:45] INFO Train time: 89.11908s. Valid time: 0.38980s. GPU RAM: 0.24/10.76 GB
[2023-06-19 11:31:45] INFO Early stopped. Since the metric logloss haven't been improved for 10 epochs.
[2023-06-19 11:31:45] INFO The best score of logloss is 0.3777 on epoch 3
[2023-06-19 11:31:45] INFO Best model checkpoint saved in ./saved/AITM/recsys/2023-06-19-11-08-56.ckpt.
