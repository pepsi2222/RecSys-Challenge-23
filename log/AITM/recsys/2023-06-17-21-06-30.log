[2023-06-17 21:06:30] INFO Log saved in /data2/home/xingmei/RecSys23/log/AITM/recsys/2023-06-17-21-06-30.log.
[2023-06-17 21:06:30] INFO Global seed set to 2022
[2023-06-17 21:06:30] INFO Load dataset from cache.
[2023-06-17 21:06:31] INFO 
Dataset Info: 

======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
interaction information: 
field        f_1          f_2          f_3          f_4          f_5          f_6          f_8          f_9          f_10         f_11         f_12         f_13         f_14         f_15         f_16         f_17         f_18         f_19         f_20         f_21         f_22         f_23         f_24         f_25         f_26         f_30         f_31         f_32         f_33         f_34         f_35         f_36         f_37         f_38         f_39         f_40         f_41         f_42         f_43         f_44         f_45         f_46         f_47         f_48         f_49         f_50         f_51         f_52         f_53         f_54         f_55         f_56         f_57         f_58         f_59         f_60         f_61         f_62         f_63         f_64         f_65         f_66         f_67         f_68         f_69         f_70         f_71         f_72         f_73         f_74         f_75         f_76         f_77         f_78         f_79         is_clicked   is_installed 
type         float        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        float        token        token        token        token        token        token        token        token        token        token        token        token        token        token        float        float        token        token        token        token        float        float        float        float        float        float        float        token        token        token        token        token        token        token        token        token        float        float        
##           -            140          6            639          7            5235         7            8            4            25           27           332          20           5855         13           50           925          20           58           36           27           5            5            4            3            3            3            5            3            3            3            3            3            3            3            3            3            8883         -            22           24           12           28           28           21           35           1829         172          103          213          390          221          517          -            -            403          826          1397         408          -            -            -            -            -            -            -            5            12           9            5            32           9            5            14           8            -            -            
======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
Total Interactions: 3646825
======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
f_1=StandardScaler()
f_43=StandardScaler()
f_58=StandardScaler()
f_59=StandardScaler()
f_64=MinMaxScaler()
f_65=StandardScaler()
f_66=StandardScaler()
f_67=StandardScaler()
f_68=StandardScaler()
f_69=StandardScaler()
f_70=StandardScaler()
[2023-06-17 21:06:31] INFO 
Model Config: 

data:
	binarized_rating_thres=None
	fm_eval=False
	neg_count=0
	sampler=None
	shuffle=False
	split_mode=entry
	split_ratio=[3387880, 97972, 160973]
	fmeval=True
	low_rating_thres=None
eval:
	batch_size=4096
	cutoff=[5, 10, 20]
	val_metrics=['logloss', 'auc', 'accuracy', 'f1', 'precision', 'recall']
	val_n_epoch=1
	test_metrics=['logloss', 'auc', 'accuracy', 'f1', 'precision', 'recall']
	topk=100
	save_path=./saved/
	binarized_prob_thres=0.5
	main_task=is_installed
model:
	embed_dim=64
	item_bias=False
	tower_mlp_layer=[128, 64]
	tower_activation=relu
	tower_dropout=0
	tower_batch_norm=False
	alpha=0.6
train:
	accelerator=gpu
	ann=None
	batch_size=512
	early_stop_mode=min
	early_stop_patience=10
	epochs=1000
	gpu=[6]
	grad_clip_norm=None
	init_method=xavier_normal
	item_batch_size=1024
	learner=adam
	learning_rate=0.001
	num_threads=10
	sampling_method=none
	sampler=uniform
	negative_count=0
	excluding_hist=False
	scheduler=None
	seed=2022
	weight_decay=1e-05
	tensorboard_path=None
	weights=None
[2023-06-17 21:06:32] INFO save_dir:./saved/
[2023-06-17 21:06:32] INFO AITM(
  (loss_fn): BCEWithLogitLoss()
  (embedding): Embeddings(
    num_features=75, embed_dim=64, reduction=mean
    (embeddings): ModuleDict(
      (f_78): Embedding(14, 64, padding_idx=0)
      (f_31): Embedding(3, 64, padding_idx=0)
      (f_16): Embedding(13, 64, padding_idx=0)
      (f_72): Embedding(12, 64, padding_idx=0)
      (f_24): Embedding(5, 64, padding_idx=0)
      (f_59): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_75): Embedding(32, 64, padding_idx=0)
      (f_46): Embedding(12, 64, padding_idx=0)
      (f_5): Embedding(7, 64, padding_idx=0)
      (f_36): Embedding(3, 64, padding_idx=0)
      (f_76): Embedding(9, 64, padding_idx=0)
      (f_71): Embedding(5, 64, padding_idx=0)
      (f_11): Embedding(25, 64, padding_idx=0)
      (f_61): Embedding(826, 64, padding_idx=0)
      (f_65): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_20): Embedding(58, 64, padding_idx=0)
      (f_79): Embedding(8, 64, padding_idx=0)
      (f_53): Embedding(103, 64, padding_idx=0)
      (f_47): Embedding(28, 64, padding_idx=0)
      (f_40): Embedding(3, 64, padding_idx=0)
      (f_26): Embedding(3, 64, padding_idx=0)
      (f_23): Embedding(5, 64, padding_idx=0)
      (f_9): Embedding(8, 64, padding_idx=0)
      (f_6): Embedding(5235, 64, padding_idx=0)
      (f_39): Embedding(3, 64, padding_idx=0)
      (f_1): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_52): Embedding(172, 64, padding_idx=0)
      (f_70): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_77): Embedding(5, 64, padding_idx=0)
      (f_3): Embedding(6, 64, padding_idx=0)
      (f_41): Embedding(3, 64, padding_idx=0)
      (f_10): Embedding(4, 64, padding_idx=0)
      (f_63): Embedding(408, 64, padding_idx=0)
      (f_22): Embedding(27, 64, padding_idx=0)
      (f_67): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_37): Embedding(3, 64, padding_idx=0)
      (f_74): Embedding(5, 64, padding_idx=0)
      (f_30): Embedding(3, 64, padding_idx=0)
      (f_19): Embedding(20, 64, padding_idx=0)
      (f_73): Embedding(9, 64, padding_idx=0)
      (f_42): Embedding(8883, 64, padding_idx=0)
      (f_69): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_13): Embedding(332, 64, padding_idx=0)
      (f_18): Embedding(925, 64, padding_idx=0)
      (f_12): Embedding(27, 64, padding_idx=0)
      (f_4): Embedding(639, 64, padding_idx=0)
      (f_54): Embedding(213, 64, padding_idx=0)
      (f_66): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_38): Embedding(3, 64, padding_idx=0)
      (f_44): Embedding(22, 64, padding_idx=0)
      (f_60): Embedding(403, 64, padding_idx=0)
      (f_68): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_45): Embedding(24, 64, padding_idx=0)
      (f_8): Embedding(7, 64, padding_idx=0)
      (f_14): Embedding(20, 64, padding_idx=0)
      (f_21): Embedding(36, 64, padding_idx=0)
      (f_55): Embedding(390, 64, padding_idx=0)
      (f_57): Embedding(517, 64, padding_idx=0)
      (f_15): Embedding(5855, 64, padding_idx=0)
      (f_49): Embedding(21, 64, padding_idx=0)
      (f_48): Embedding(28, 64, padding_idx=0)
      (f_62): Embedding(1397, 64, padding_idx=0)
      (f_2): Embedding(140, 64, padding_idx=0)
      (f_33): Embedding(3, 64, padding_idx=0)
      (f_64): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_32): Embedding(5, 64, padding_idx=0)
      (f_34): Embedding(3, 64, padding_idx=0)
      (f_35): Embedding(3, 64, padding_idx=0)
      (f_56): Embedding(221, 64, padding_idx=0)
      (f_50): Embedding(35, 64, padding_idx=0)
      (f_51): Embedding(1829, 64, padding_idx=0)
      (f_43): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_58): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_25): Embedding(4, 64, padding_idx=0)
      (f_17): Embedding(50, 64, padding_idx=0)
    )
  )
  (towers): ModuleDict(
    (is_clicked): MLPModule(
      (model): Sequential(
        (0): Dropout(p=0, inplace=False)
        (1): Linear(in_features=4800, out_features=128, bias=True)
        (2): ReLU()
        (3): Dropout(p=0, inplace=False)
        (4): Linear(in_features=128, out_features=64, bias=True)
        (5): ReLU()
      )
    )
    (is_installed): MLPModule(
      (model): Sequential(
        (0): Dropout(p=0, inplace=False)
        (1): Linear(in_features=4800, out_features=128, bias=True)
        (2): ReLU()
        (3): Dropout(p=0, inplace=False)
        (4): Linear(in_features=128, out_features=64, bias=True)
        (5): ReLU()
      )
    )
  )
  (att_layers): ModuleDict(
    (is_installed): AttentionLayer(
      (attn_layer): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
      )
    )
  )
  (info_layers): ModuleDict(
    (is_clicked): Sequential(
      (0): Linear(in_features=64, out_features=64, bias=True)
      (1): ReLU()
    )
  )
  (fc_layers): ModuleDict(
    (is_clicked): Linear(in_features=64, out_features=1, bias=True)
    (is_installed): Linear(in_features=64, out_features=1, bias=True)
  )
)
[2023-06-17 21:06:32] INFO GPU id [6] are selected.
[2023-06-17 21:09:41] INFO Training: Epoch=  0 [train_loss_0=0.3084 is_clicked logloss=0.5213 accuracy=0.7730 f1=0.6342 precision=0.7626 recall=0.5429 auc=0.7466 train_loss_0=0.3150 is_installed logloss=0.4261 accuracy=0.8167 f1=0.1527 precision=0.5707 recall=0.0882 auc=0.7646 train_loss_0=0.3013]
[2023-06-17 21:09:41] INFO Train time: 188.27201s. Valid time: 0.62489s. GPU RAM: 0.27/10.76 GB
[2023-06-17 21:09:41] INFO logloss improved. Best value: 0.4261
[2023-06-17 21:12:51] INFO Training: Epoch=  1 [train_loss_0=0.2951 is_clicked logloss=0.5089 accuracy=0.7751 f1=0.6379 precision=0.7660 recall=0.5466 auc=0.7736 train_loss_0=0.2999 is_installed logloss=0.4165 accuracy=0.8166 f1=0.2501 precision=0.5360 recall=0.1633 auc=0.7812 train_loss_0=0.2901]
[2023-06-17 21:12:51] INFO Train time: 189.22994s. Valid time: 0.61292s. GPU RAM: 0.28/10.76 GB
[2023-06-17 21:12:52] INFO logloss improved. Best value: 0.4165
[2023-06-17 21:15:59] INFO Training: Epoch=  2 [train_loss_0=0.2920 is_clicked logloss=0.4779 accuracy=0.7984 f1=0.6602 precision=0.8482 recall=0.5406 auc=0.7900 train_loss_0=0.2966 is_installed logloss=0.4151 accuracy=0.8207 f1=0.1737 precision=0.6351 recall=0.1007 auc=0.8057 train_loss_0=0.2872]
[2023-06-17 21:15:59] INFO Train time: 186.41269s. Valid time: 0.59256s. GPU RAM: 0.28/10.76 GB
[2023-06-17 21:16:00] INFO logloss improved. Best value: 0.4151
[2023-06-17 21:19:07] INFO Training: Epoch=  3 [train_loss_0=0.2905 is_clicked logloss=0.4670 accuracy=0.7938 f1=0.6579 precision=0.8249 recall=0.5472 auc=0.7993 train_loss_0=0.2952 is_installed logloss=0.4054 accuracy=0.8204 f1=0.1958 precision=0.6099 recall=0.1167 auc=0.8012 train_loss_0=0.2857]
[2023-06-17 21:19:07] INFO Train time: 186.51533s. Valid time: 0.59061s. GPU RAM: 0.28/10.76 GB
[2023-06-17 21:19:08] INFO logloss improved. Best value: 0.4054
[2023-06-17 21:22:18] INFO Training: Epoch=  4 [train_loss_0=0.2896 is_clicked logloss=0.5039 accuracy=0.7789 f1=0.6494 precision=0.7637 recall=0.5649 auc=0.7772 train_loss_0=0.2944 is_installed logloss=0.4000 accuracy=0.8194 f1=0.2505 precision=0.5639 recall=0.1611 auc=0.7932 train_loss_0=0.2848]
[2023-06-17 21:22:18] INFO Train time: 189.10185s. Valid time: 0.56773s. GPU RAM: 0.28/10.76 GB
[2023-06-17 21:22:18] INFO logloss improved. Best value: 0.4000
[2023-06-17 21:25:27] INFO Training: Epoch=  5 [train_loss_0=0.2891 is_clicked logloss=0.5064 accuracy=0.7834 f1=0.6473 precision=0.7897 recall=0.5485 auc=0.7769 train_loss_0=0.2939 is_installed logloss=0.4032 accuracy=0.8203 f1=0.2037 precision=0.6013 recall=0.1227 auc=0.8007 train_loss_0=0.2841]
[2023-06-17 21:25:27] INFO Train time: 187.87092s. Valid time: 0.54727s. GPU RAM: 0.28/10.76 GB
[2023-06-17 21:28:34] INFO Training: Epoch=  6 [train_loss_0=0.2885 is_clicked logloss=0.4934 accuracy=0.7864 f1=0.6561 precision=0.7880 recall=0.5621 auc=0.7940 train_loss_0=0.2934 is_installed logloss=0.3967 accuracy=0.8203 f1=0.2482 precision=0.5750 recall=0.1584 auc=0.8021 train_loss_0=0.2836]
[2023-06-17 21:28:34] INFO Train time: 186.46921s. Valid time: 0.64760s. GPU RAM: 0.28/10.76 GB
[2023-06-17 21:28:35] INFO logloss improved. Best value: 0.3967
[2023-06-17 21:31:43] INFO Training: Epoch=  7 [train_loss_0=0.2882 is_clicked logloss=0.5154 accuracy=0.7801 f1=0.6470 precision=0.7737 recall=0.5561 auc=0.7784 train_loss_0=0.2929 is_installed logloss=0.4005 accuracy=0.8186 f1=0.2352 precision=0.5608 recall=0.1489 auc=0.7980 train_loss_0=0.2833]
[2023-06-17 21:31:43] INFO Train time: 187.63464s. Valid time: 0.57078s. GPU RAM: 0.28/10.76 GB
[2023-06-17 21:34:58] INFO Training: Epoch=  8 [train_loss_0=0.2878 is_clicked logloss=0.5096 accuracy=0.7862 f1=0.6484 precision=0.8024 recall=0.5441 auc=0.7822 train_loss_0=0.2927 is_installed logloss=0.4050 accuracy=0.8191 f1=0.2085 precision=0.5784 recall=0.1273 auc=0.8017 train_loss_0=0.2829]
[2023-06-17 21:34:58] INFO Train time: 194.12805s. Valid time: 0.54151s. GPU RAM: 0.28/10.76 GB
[2023-06-17 21:38:11] INFO Training: Epoch=  9 [train_loss_0=0.2876 is_clicked logloss=0.5025 accuracy=0.7846 f1=0.6519 precision=0.7866 recall=0.5567 auc=0.7813 train_loss_0=0.2924 is_installed logloss=0.3969 accuracy=0.8187 f1=0.2470 precision=0.5572 recall=0.1587 auc=0.7972 train_loss_0=0.2827]
[2023-06-17 21:38:11] INFO Train time: 192.61432s. Valid time: 0.54223s. GPU RAM: 0.28/10.76 GB
[2023-06-17 21:41:24] INFO Training: Epoch= 10 [train_loss_0=0.2874 is_clicked logloss=0.5038 accuracy=0.7784 f1=0.6557 precision=0.7508 recall=0.5820 auc=0.7853 train_loss_0=0.2921 is_installed logloss=0.3948 accuracy=0.8179 f1=0.2762 precision=0.5414 recall=0.1855 auc=0.7981 train_loss_0=0.2826]
[2023-06-17 21:41:24] INFO Train time: 192.28741s. Valid time: 0.56398s. GPU RAM: 0.28/10.76 GB
[2023-06-17 21:41:25] INFO logloss improved. Best value: 0.3948
[2023-06-17 21:44:36] INFO Training: Epoch= 11 [train_loss_0=0.2872 is_clicked logloss=0.4880 accuracy=0.7833 f1=0.6528 precision=0.7786 recall=0.5621 auc=0.8020 train_loss_0=0.2920 is_installed logloss=0.3947 accuracy=0.8196 f1=0.2427 precision=0.5687 recall=0.1543 auc=0.8064 train_loss_0=0.2823]
[2023-06-17 21:44:36] INFO Train time: 190.50600s. Valid time: 0.57319s. GPU RAM: 0.28/10.76 GB
[2023-06-17 21:44:37] INFO logloss improved. Best value: 0.3947
[2023-06-17 21:47:48] INFO Training: Epoch= 12 [train_loss_0=0.2870 is_clicked logloss=0.5024 accuracy=0.7851 f1=0.6499 precision=0.7936 recall=0.5504 auc=0.7913 train_loss_0=0.2918 is_installed logloss=0.4024 accuracy=0.8182 f1=0.2030 precision=0.5686 recall=0.1236 auc=0.8039 train_loss_0=0.2821]
[2023-06-17 21:47:48] INFO Train time: 190.60356s. Valid time: 0.60150s. GPU RAM: 0.28/10.76 GB
[2023-06-17 21:51:04] INFO Training: Epoch= 13 [train_loss_0=0.2869 is_clicked logloss=0.5029 accuracy=0.7853 f1=0.6538 precision=0.7865 recall=0.5595 auc=0.7904 train_loss_0=0.2916 is_installed logloss=0.3985 accuracy=0.8183 f1=0.2076 precision=0.5679 recall=0.1270 auc=0.8034 train_loss_0=0.2820]
[2023-06-17 21:51:04] INFO Train time: 195.12007s. Valid time: 0.57554s. GPU RAM: 0.28/10.76 GB
[2023-06-17 21:54:14] INFO Training: Epoch= 14 [train_loss_0=0.2867 is_clicked logloss=0.4926 accuracy=0.7889 f1=0.6579 precision=0.7974 recall=0.5600 auc=0.7884 train_loss_0=0.2915 is_installed logloss=0.3981 accuracy=0.8200 f1=0.2042 precision=0.5969 recall=0.1233 auc=0.8005 train_loss_0=0.2818]
[2023-06-17 21:54:14] INFO Train time: 188.99061s. Valid time: 0.38243s. GPU RAM: 0.28/10.76 GB
[2023-06-17 21:57:13] INFO Training: Epoch= 15 [train_loss_0=0.2866 is_clicked logloss=0.5281 accuracy=0.7685 f1=0.6395 precision=0.7342 recall=0.5665 auc=0.7705 train_loss_0=0.2914 is_installed logloss=0.4011 accuracy=0.8177 f1=0.2241 precision=0.5539 recall=0.1406 auc=0.7934 train_loss_0=0.2817]
[2023-06-17 21:57:13] INFO Train time: 179.14952s. Valid time: 0.35586s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:00:16] INFO Training: Epoch= 16 [train_loss_0=0.2864 is_clicked logloss=0.4886 accuracy=0.7851 f1=0.6508 precision=0.7916 recall=0.5527 auc=0.7957 train_loss_0=0.2912 is_installed logloss=0.4003 accuracy=0.8216 f1=0.2009 precision=0.6265 recall=0.1197 auc=0.8143 train_loss_0=0.2815]
[2023-06-17 22:00:16] INFO Train time: 181.52666s. Valid time: 0.36255s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:03:18] INFO Training: Epoch= 17 [train_loss_0=0.2864 is_clicked logloss=0.5045 accuracy=0.7847 f1=0.6492 precision=0.7928 recall=0.5498 auc=0.7875 train_loss_0=0.2911 is_installed logloss=0.4042 accuracy=0.8184 f1=0.2179 precision=0.5651 recall=0.1351 auc=0.8024 train_loss_0=0.2815]
[2023-06-17 22:03:18] INFO Train time: 181.81975s. Valid time: 0.41130s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:06:17] INFO Training: Epoch= 18 [train_loss_0=0.2863 is_clicked logloss=0.5100 accuracy=0.7790 f1=0.6493 precision=0.7642 recall=0.5645 auc=0.7903 train_loss_0=0.2911 is_installed logloss=0.3952 accuracy=0.8178 f1=0.2472 precision=0.5478 recall=0.1598 auc=0.8013 train_loss_0=0.2814]
[2023-06-17 22:06:17] INFO Train time: 178.28720s. Valid time: 0.35374s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:09:16] INFO Training: Epoch= 19 [train_loss_0=0.2862 is_clicked logloss=0.4889 accuracy=0.7900 f1=0.6518 precision=0.8164 recall=0.5425 auc=0.7876 train_loss_0=0.2910 is_installed logloss=0.3944 accuracy=0.8197 f1=0.2049 precision=0.5916 recall=0.1240 auc=0.8039 train_loss_0=0.2813]
[2023-06-17 22:09:16] INFO Train time: 178.93730s. Valid time: 0.34461s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:09:17] INFO logloss improved. Best value: 0.3944
[2023-06-17 22:12:14] INFO Training: Epoch= 20 [train_loss_0=0.2861 is_clicked logloss=0.5138 accuracy=0.7789 f1=0.6458 precision=0.7699 recall=0.5562 auc=0.7841 train_loss_0=0.2909 is_installed logloss=0.3986 accuracy=0.8182 f1=0.2239 precision=0.5604 recall=0.1399 auc=0.8043 train_loss_0=0.2813]
[2023-06-17 22:12:14] INFO Train time: 176.96189s. Valid time: 0.39263s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:15:14] INFO Training: Epoch= 21 [train_loss_0=0.2861 is_clicked logloss=0.5180 accuracy=0.7801 f1=0.6482 precision=0.7716 recall=0.5589 auc=0.7863 train_loss_0=0.2908 is_installed logloss=0.4068 accuracy=0.8159 f1=0.2383 precision=0.5307 recall=0.1537 auc=0.7899 train_loss_0=0.2812]
[2023-06-17 22:15:14] INFO Train time: 178.68446s. Valid time: 0.34475s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:18:11] INFO Training: Epoch= 22 [train_loss_0=0.2860 is_clicked logloss=0.5050 accuracy=0.7810 f1=0.6471 precision=0.7778 recall=0.5541 auc=0.7833 train_loss_0=0.2908 is_installed logloss=0.4030 accuracy=0.8189 f1=0.2254 precision=0.5679 recall=0.1408 auc=0.7952 train_loss_0=0.2812]
[2023-06-17 22:18:11] INFO Train time: 176.79902s. Valid time: 0.34645s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:21:11] INFO Training: Epoch= 23 [train_loss_0=0.2860 is_clicked logloss=0.5054 accuracy=0.7793 f1=0.6454 precision=0.7725 recall=0.5543 auc=0.7828 train_loss_0=0.2907 is_installed logloss=0.4067 accuracy=0.8195 f1=0.2204 precision=0.5783 recall=0.1362 auc=0.7958 train_loss_0=0.2812]
[2023-06-17 22:21:11] INFO Train time: 179.54641s. Valid time: 0.35825s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:24:09] INFO Training: Epoch= 24 [train_loss_0=0.2859 is_clicked logloss=0.4838 accuracy=0.7931 f1=0.6508 precision=0.8378 recall=0.5321 auc=0.7892 train_loss_0=0.2906 is_installed logloss=0.4020 accuracy=0.8200 f1=0.1875 precision=0.6074 recall=0.1110 auc=0.8067 train_loss_0=0.2811]
[2023-06-17 22:24:09] INFO Train time: 177.94390s. Valid time: 0.34335s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:27:06] INFO Training: Epoch= 25 [train_loss_0=0.2858 is_clicked logloss=0.5042 accuracy=0.7849 f1=0.6509 precision=0.7901 recall=0.5535 auc=0.7988 train_loss_0=0.2907 is_installed logloss=0.4023 accuracy=0.8166 f1=0.2511 precision=0.5356 recall=0.1641 auc=0.7986 train_loss_0=0.2809]
[2023-06-17 22:27:06] INFO Train time: 176.10528s. Valid time: 0.36379s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:30:08] INFO Training: Epoch= 26 [train_loss_0=0.2858 is_clicked logloss=0.4918 accuracy=0.7825 f1=0.6512 precision=0.7775 recall=0.5603 auc=0.7941 train_loss_0=0.2905 is_installed logloss=0.3967 accuracy=0.8189 f1=0.2257 precision=0.5677 recall=0.1409 auc=0.8018 train_loss_0=0.2809]
[2023-06-17 22:30:08] INFO Train time: 181.97504s. Valid time: 0.36140s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:33:09] INFO Training: Epoch= 27 [train_loss_0=0.2858 is_clicked logloss=0.5229 accuracy=0.7693 f1=0.6385 precision=0.7387 recall=0.5624 auc=0.7728 train_loss_0=0.2906 is_installed logloss=0.4065 accuracy=0.8153 f1=0.2700 precision=0.5210 recall=0.1823 auc=0.7833 train_loss_0=0.2810]
[2023-06-17 22:33:09] INFO Train time: 180.12017s. Valid time: 0.36538s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:36:07] INFO Training: Epoch= 28 [train_loss_0=0.2857 is_clicked logloss=0.5298 accuracy=0.7616 f1=0.6305 precision=0.7195 recall=0.5612 auc=0.7689 train_loss_0=0.2905 is_installed logloss=0.4018 accuracy=0.8182 f1=0.2273 precision=0.5583 recall=0.1428 auc=0.7946 train_loss_0=0.2809]
[2023-06-17 22:36:07] INFO Train time: 177.59900s. Valid time: 0.34740s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:39:06] INFO Training: Epoch= 29 [train_loss_0=0.2857 is_clicked logloss=0.5177 accuracy=0.7762 f1=0.6416 precision=0.7647 recall=0.5526 auc=0.7812 train_loss_0=0.2905 is_installed logloss=0.4015 accuracy=0.8185 f1=0.2176 precision=0.5662 recall=0.1348 auc=0.8051 train_loss_0=0.2808]
[2023-06-17 22:39:06] INFO Train time: 178.67109s. Valid time: 0.35262s. GPU RAM: 0.28/10.76 GB
[2023-06-17 22:39:06] INFO Early stopped. Since the metric logloss haven't been improved for 10 epochs.
[2023-06-17 22:39:06] INFO The best score of logloss is 0.3944 on epoch 19
[2023-06-17 22:39:06] INFO Best model checkpoint saved in ./saved/AITM/recsys/2023-06-17-21-06-30.ckpt.
[2023-06-17 22:39:22] INFO Predictions saved in ./predictions/AITM/2023-06-17-22-39-06['is_clicked', 'is_installed'].csv
