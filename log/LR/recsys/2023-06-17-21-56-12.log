[2023-06-17 21:56:12] INFO Log saved in /data2/home/xingmei/RecSys23/log/LR/recsys/2023-06-17-21-56-12.log.
[2023-06-17 21:56:12] INFO Global seed set to 2022
[2023-06-17 21:56:12] INFO Load dataset from cache.
[2023-06-17 21:56:14] INFO 
Dataset Info: 

=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
interaction information: 
field        f_1          f_2          f_3          f_4          f_5          f_6          f_8          f_9          f_10         f_11         f_12         f_13         f_14         f_15         f_16         f_17         f_18         f_19         f_20         f_21         f_22         f_23         f_24         f_25         f_26         f_30         f_31         f_32         f_33         f_34         f_35         f_36         f_37         f_38         f_39         f_40         f_41         f_42         f_43         f_44         f_45         f_46         f_47         f_48         f_49         f_50         f_51         f_52         f_53         f_54         f_55         f_56         f_57         f_58         f_59         f_60         f_61         f_62         f_63         f_64         f_65         f_66         f_67         f_68         f_69         f_70         f_71         f_72         f_73         f_74         f_75         f_76         f_77         f_78         f_79         is_installed 
type         float        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        float        token        token        token        token        token        token        token        token        token        token        token        token        token        token        float        float        token        token        token        token        float        float        float        float        float        float        float        token        token        token        token        token        token        token        token        token        float        
##           -            140          6            639          7            5235         7            8            4            25           27           332          20           5855         13           50           925          20           58           36           27           5            5            4            3            3            3            5            3            3            3            3            3            3            3            3            3            8883         -            22           24           12           28           28           21           35           1829         172          103          213          390          221          517          -            -            403          826          1397         408          -            -            -            -            -            -            -            5            12           9            5            32           9            5            14           8            -            
=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
Total Interactions: 3646825
=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
f_1=StandardScaler()
f_43=StandardScaler()
f_58=StandardScaler()
f_59=StandardScaler()
f_64=MinMaxScaler()
f_65=StandardScaler()
f_66=StandardScaler()
f_67=StandardScaler()
f_68=StandardScaler()
f_69=StandardScaler()
f_70=StandardScaler()
[2023-06-17 21:56:14] INFO 
Model Config: 

data:
	binarized_rating_thres=None
	fm_eval=False
	neg_count=0
	sampler=None
	shuffle=False
	split_mode=entry
	split_ratio=[3387880, 97972, 160973]
	fmeval=True
	low_rating_thres=None
eval:
	batch_size=4096
	cutoff=[5, 10, 20]
	val_metrics=['logloss', 'auc', 'accuracy', 'f1', 'precision', 'recall']
	val_n_epoch=1
	test_metrics=['logloss', 'auc', 'accuracy', 'f1', 'precision', 'recall']
	topk=100
	save_path=./saved/
	binarized_prob_thres=0.5
model:
	embed_dim=1
	item_bias=False
train:
	accelerator=gpu
	ann=None
	batch_size=512
	early_stop_mode=min
	early_stop_patience=10
	epochs=1000
	gpu=[2]
	grad_clip_norm=None
	init_method=xavier_normal
	item_batch_size=1024
	learner=adam
	learning_rate=0.001
	num_threads=10
	sampling_method=none
	sampler=uniform
	negative_count=0
	excluding_hist=False
	scheduler=None
	seed=2022
	weight_decay=0.0
	tensorboard_path=None
[2023-06-17 21:56:14] INFO save_dir:./saved/
[2023-06-17 21:56:14] INFO LR(
  (loss_fn): BCEWithLogitLoss()
  (linear): LinearLayer(
    bias=True
    (embeddings): ModuleDict(
      (f_22): Embedding(27, 1, padding_idx=0)
      (f_9): Embedding(8, 1, padding_idx=0)
      (f_12): Embedding(27, 1, padding_idx=0)
      (f_70): DenseEmbedding(
        embedding_dim=1, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=1, bias=False)
      )
      (f_68): DenseEmbedding(
        embedding_dim=1, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=1, bias=False)
      )
      (f_2): Embedding(140, 1, padding_idx=0)
      (f_63): Embedding(408, 1, padding_idx=0)
      (f_8): Embedding(7, 1, padding_idx=0)
      (f_47): Embedding(28, 1, padding_idx=0)
      (f_66): DenseEmbedding(
        embedding_dim=1, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=1, bias=False)
      )
      (f_55): Embedding(390, 1, padding_idx=0)
      (f_56): Embedding(221, 1, padding_idx=0)
      (f_61): Embedding(826, 1, padding_idx=0)
      (f_14): Embedding(20, 1, padding_idx=0)
      (f_4): Embedding(639, 1, padding_idx=0)
      (f_17): Embedding(50, 1, padding_idx=0)
      (f_18): Embedding(925, 1, padding_idx=0)
      (f_5): Embedding(7, 1, padding_idx=0)
      (f_71): Embedding(5, 1, padding_idx=0)
      (f_3): Embedding(6, 1, padding_idx=0)
      (f_32): Embedding(5, 1, padding_idx=0)
      (f_13): Embedding(332, 1, padding_idx=0)
      (f_49): Embedding(21, 1, padding_idx=0)
      (f_69): DenseEmbedding(
        embedding_dim=1, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=1, bias=False)
      )
      (f_72): Embedding(12, 1, padding_idx=0)
      (f_11): Embedding(25, 1, padding_idx=0)
      (f_33): Embedding(3, 1, padding_idx=0)
      (f_34): Embedding(3, 1, padding_idx=0)
      (f_57): Embedding(517, 1, padding_idx=0)
      (f_59): DenseEmbedding(
        embedding_dim=1, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=1, bias=False)
      )
      (f_25): Embedding(4, 1, padding_idx=0)
      (f_39): Embedding(3, 1, padding_idx=0)
      (f_48): Embedding(28, 1, padding_idx=0)
      (f_41): Embedding(3, 1, padding_idx=0)
      (f_79): Embedding(8, 1, padding_idx=0)
      (f_24): Embedding(5, 1, padding_idx=0)
      (f_23): Embedding(5, 1, padding_idx=0)
      (f_53): Embedding(103, 1, padding_idx=0)
      (f_15): Embedding(5855, 1, padding_idx=0)
      (f_31): Embedding(3, 1, padding_idx=0)
      (f_60): Embedding(403, 1, padding_idx=0)
      (f_44): Embedding(22, 1, padding_idx=0)
      (f_64): DenseEmbedding(
        embedding_dim=1, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=1, bias=False)
      )
      (f_10): Embedding(4, 1, padding_idx=0)
      (f_30): Embedding(3, 1, padding_idx=0)
      (f_62): Embedding(1397, 1, padding_idx=0)
      (f_36): Embedding(3, 1, padding_idx=0)
      (f_1): DenseEmbedding(
        embedding_dim=1, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=1, bias=False)
      )
      (f_42): Embedding(8883, 1, padding_idx=0)
      (f_40): Embedding(3, 1, padding_idx=0)
      (f_65): DenseEmbedding(
        embedding_dim=1, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=1, bias=False)
      )
      (f_58): DenseEmbedding(
        embedding_dim=1, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=1, bias=False)
      )
      (f_38): Embedding(3, 1, padding_idx=0)
      (f_35): Embedding(3, 1, padding_idx=0)
      (f_78): Embedding(14, 1, padding_idx=0)
      (f_51): Embedding(1829, 1, padding_idx=0)
      (f_21): Embedding(36, 1, padding_idx=0)
      (f_67): DenseEmbedding(
        embedding_dim=1, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=1, bias=False)
      )
      (f_45): Embedding(24, 1, padding_idx=0)
      (f_37): Embedding(3, 1, padding_idx=0)
      (f_76): Embedding(9, 1, padding_idx=0)
      (f_20): Embedding(58, 1, padding_idx=0)
      (f_50): Embedding(35, 1, padding_idx=0)
      (f_77): Embedding(5, 1, padding_idx=0)
      (f_16): Embedding(13, 1, padding_idx=0)
      (f_43): DenseEmbedding(
        embedding_dim=1, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=1, bias=False)
      )
      (f_6): Embedding(5235, 1, padding_idx=0)
      (f_74): Embedding(5, 1, padding_idx=0)
      (f_73): Embedding(9, 1, padding_idx=0)
      (f_52): Embedding(172, 1, padding_idx=0)
      (f_46): Embedding(12, 1, padding_idx=0)
      (f_19): Embedding(20, 1, padding_idx=0)
      (f_54): Embedding(213, 1, padding_idx=0)
      (f_75): Embedding(32, 1, padding_idx=0)
      (f_26): Embedding(3, 1, padding_idx=0)
    )
  )
)
[2023-06-17 21:56:14] INFO GPU id [2] are selected.
[2023-06-17 21:59:18] INFO Training: Epoch=  0 [logloss=0.4082 accuracy=0.8188 f1=0.1516 precision=0.6199 recall=0.0864 auc=0.8058 train_loss_0=0.3351]
[2023-06-17 21:59:18] INFO Train time: 183.02695s. Valid time: 0.65473s. GPU RAM: 0.03/10.76 GB
[2023-06-17 21:59:18] INFO logloss improved. Best value: 0.4082
[2023-06-17 22:02:34] INFO Training: Epoch=  1 [logloss=0.4015 accuracy=0.8202 f1=0.2204 precision=0.5890 recall=0.1357 auc=0.8083 train_loss_0=0.2957]
[2023-06-17 22:02:34] INFO Train time: 195.23302s. Valid time: 0.61223s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:02:34] INFO logloss improved. Best value: 0.4015
[2023-06-17 22:05:46] INFO Training: Epoch=  2 [logloss=0.4005 accuracy=0.8201 f1=0.2420 precision=0.5757 recall=0.1533 auc=0.8086 train_loss_0=0.2942]
[2023-06-17 22:05:46] INFO Train time: 191.40534s. Valid time: 0.62553s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:05:46] INFO logloss improved. Best value: 0.4005
[2023-06-17 22:08:58] INFO Training: Epoch=  3 [logloss=0.3951 accuracy=0.8203 f1=0.3064 precision=0.5547 recall=0.2118 auc=0.8078 train_loss_0=0.2936]
[2023-06-17 22:08:58] INFO Train time: 191.36991s. Valid time: 0.59473s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:08:58] INFO logloss improved. Best value: 0.3951
[2023-06-17 22:12:12] INFO Training: Epoch=  4 [logloss=0.3947 accuracy=0.8201 f1=0.3061 precision=0.5525 recall=0.2118 auc=0.8081 train_loss_0=0.2932]
[2023-06-17 22:12:12] INFO Train time: 192.89571s. Valid time: 0.62895s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:12:12] INFO logloss improved. Best value: 0.3947
[2023-06-17 22:15:19] INFO Training: Epoch=  5 [logloss=0.3903 accuracy=0.8178 f1=0.3819 precision=0.5244 recall=0.3006 auc=0.8079 train_loss_0=0.2930]
[2023-06-17 22:15:19] INFO Train time: 187.07130s. Valid time: 0.38102s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:15:19] INFO logloss improved. Best value: 0.3903
[2023-06-17 22:17:50] INFO Training: Epoch=  6 [logloss=0.3913 accuracy=0.8186 f1=0.3597 precision=0.5312 recall=0.2722 auc=0.8073 train_loss_0=0.2929]
[2023-06-17 22:17:50] INFO Train time: 150.68798s. Valid time: 0.37843s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:20:22] INFO Training: Epoch=  7 [logloss=0.3940 accuracy=0.8183 f1=0.3575 precision=0.5305 recall=0.2699 auc=0.8057 train_loss_0=0.2927]
[2023-06-17 22:20:22] INFO Train time: 151.35216s. Valid time: 0.37506s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:22:53] INFO Training: Epoch=  8 [logloss=0.3924 accuracy=0.8168 f1=0.3852 precision=0.5190 recall=0.3066 auc=0.8054 train_loss_0=0.2927]
[2023-06-17 22:22:53] INFO Train time: 150.29703s. Valid time: 0.39806s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:25:27] INFO Training: Epoch=  9 [logloss=0.3932 accuracy=0.8173 f1=0.3782 precision=0.5223 recall=0.2967 auc=0.8051 train_loss_0=0.2926]
[2023-06-17 22:25:27] INFO Train time: 153.67071s. Valid time: 0.37921s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:28:02] INFO Training: Epoch= 10 [logloss=0.3938 accuracy=0.8183 f1=0.3654 precision=0.5290 recall=0.2793 auc=0.8056 train_loss_0=0.2925]
[2023-06-17 22:28:02] INFO Train time: 154.30617s. Valid time: 0.38746s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:30:35] INFO Training: Epoch= 11 [logloss=0.3934 accuracy=0.8148 f1=0.4073 precision=0.5092 recall=0.3398 auc=0.8057 train_loss_0=0.2925]
[2023-06-17 22:30:35] INFO Train time: 153.12062s. Valid time: 0.38860s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:33:09] INFO Training: Epoch= 12 [logloss=0.3945 accuracy=0.8164 f1=0.3837 precision=0.5176 recall=0.3052 auc=0.8035 train_loss_0=0.2924]
[2023-06-17 22:33:09] INFO Train time: 153.73700s. Valid time: 0.39960s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:35:44] INFO Training: Epoch= 13 [logloss=0.3943 accuracy=0.8158 f1=0.3908 precision=0.5141 recall=0.3155 auc=0.8041 train_loss_0=0.2924]
[2023-06-17 22:35:44] INFO Train time: 154.39982s. Valid time: 0.36476s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:38:10] INFO Training: Epoch= 14 [logloss=0.3952 accuracy=0.8159 f1=0.3924 precision=0.5148 recall=0.3174 auc=0.8035 train_loss_0=0.2924]
[2023-06-17 22:38:10] INFO Train time: 145.73537s. Valid time: 0.21906s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:40:31] INFO Training: Epoch= 15 [logloss=0.3954 accuracy=0.8145 f1=0.4107 precision=0.5080 recall=0.3450 auc=0.8033 train_loss_0=0.2923]
[2023-06-17 22:40:31] INFO Train time: 140.56067s. Valid time: 0.38968s. GPU RAM: 0.04/10.76 GB
[2023-06-17 22:40:31] INFO Early stopped. Since the metric logloss haven't been improved for 10 epochs.
[2023-06-17 22:40:31] INFO The best score of logloss is 0.3903 on epoch 5
[2023-06-17 22:40:31] INFO Best model checkpoint saved in ./saved/LR/recsys/2023-06-17-21-56-12.ckpt.
[2023-06-17 22:40:40] INFO Predictions saved in ./predictions/LR/2023-06-17-22-40-31is_installed.csv
