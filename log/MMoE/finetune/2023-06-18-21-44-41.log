[2023-06-18 21:44:41] INFO Log saved in /data2/home/xingmei/RecSys23/log/MMoE/finetune/2023-06-18-21-44-41.log.
[2023-06-18 21:44:41] INFO Global seed set to 2022
[2023-06-18 21:44:41] INFO dataset is read from /data2/home/xingmei/RecSys23/data.
[2023-06-18 21:45:53] INFO 
Dataset Info: 

======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
interaction information: 
field        f_1          f_2          f_3          f_4          f_5          f_6          f_8          f_9          f_10         f_11         f_12         f_13         f_14         f_15         f_16         f_17         f_18         f_19         f_20         f_21         f_22         f_23         f_24         f_25         f_26         f_30         f_31         f_32         f_33         f_34         f_35         f_36         f_37         f_38         f_39         f_40         f_41         f_42         f_43         f_44         f_45         f_46         f_47         f_48         f_49         f_50         f_51         f_52         f_53         f_54         f_55         f_56         f_57         f_58         f_59         f_60         f_61         f_62         f_63         f_64         f_65         f_66         f_67         f_68         f_69         f_70         f_71         f_72         f_73         f_74         f_75         f_76         f_77         f_78         f_79         is_clicked   is_installed 
type         float        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        token        float        token        token        token        token        token        token        token        token        token        token        token        token        token        token        float        float        token        token        token        token        float        float        float        float        float        float        float        token        token        token        token        token        token        token        token        token        float        float        
##           -            136          6            631          7            4455         7            8            4            25           25           206          19           4277         11           42           543          20           56           35           25           5            5            4            3            3            3            5            3            3            3            3            3            3            3            3            3            6725         -            18           19           11           21           21           15           22           1725         133          85           172          306          182          415          -            -            232          584          1032         298          -            -            -            -            -            -            -            5            12           9            5            32           9            5            11           7            -            -            
======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
Total Interactions: 1045756
======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
f_1=StandardScaler()
f_43=StandardScaler()
f_58=StandardScaler()
f_59=StandardScaler()
f_64=MinMaxScaler()
f_65=StandardScaler()
f_66=StandardScaler()
f_67=StandardScaler()
f_68=StandardScaler()
f_69=StandardScaler()
f_70=StandardScaler()
[2023-06-18 21:45:53] INFO 
Model Config: 

data:
	binarized_rating_thres=None
	fm_eval=False
	neg_count=0
	sampler=None
	shuffle=False
	split_mode=entry
	split_ratio=[1016364, 29392, 0]
	fmeval=True
	low_rating_thres=None
eval:
	batch_size=4096
	cutoff=[5, 10, 20]
	val_metrics=['logloss', 'auc', 'accuracy', 'f1', 'precision', 'recall']
	val_n_epoch=1
	test_metrics=['logloss', 'auc', 'accuracy', 'f1', 'precision', 'recall']
	topk=100
	save_path=./saved/
	binarized_prob_thres=0.5
	main_task=is_installed
model:
	embed_dim=64
	item_bias=False
	num_experts=4
	expert_mlp_layer=[128, 128]
	expert_activation=relu
	expert_dropout=0.1
	expert_batch_norm=False
	gate_mlp_layer=[128]
	gate_activation=relu
	gate_dropout=0.1
	gate_batch_norm=False
	tower_mlp_layer=[128]
	tower_activation=relu
	tower_dropout=0.1
	tower_batch_norm=False
train:
	accelerator=gpu
	ann=None
	batch_size=512
	early_stop_mode=min
	early_stop_patience=10
	epochs=1000
	gpu=[0]
	grad_clip_norm=None
	init_method=xavier_normal
	item_batch_size=1024
	learner=adam
	learning_rate=0.001
	num_threads=10
	sampling_method=none
	sampler=uniform
	negative_count=0
	excluding_hist=False
	scheduler=None
	seed=2022
	weight_decay=1e-05
	tensorboard_path=None
	weights=[0.2, 0.8]
[2023-06-18 21:45:54] INFO save_dir:./saved/
[2023-06-18 21:45:54] INFO MMoE(
  (loss_fn): BCEWithLogitLoss()
  (embedding): Embeddings(
    num_features=75, embed_dim=64, reduction=mean
    (embeddings): ModuleDict(
      (f_52): Embedding(133, 64, padding_idx=0)
      (f_54): Embedding(172, 64, padding_idx=0)
      (f_13): Embedding(206, 64, padding_idx=0)
      (f_38): Embedding(3, 64, padding_idx=0)
      (f_14): Embedding(19, 64, padding_idx=0)
      (f_41): Embedding(3, 64, padding_idx=0)
      (f_68): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_73): Embedding(9, 64, padding_idx=0)
      (f_57): Embedding(415, 64, padding_idx=0)
      (f_47): Embedding(21, 64, padding_idx=0)
      (f_55): Embedding(306, 64, padding_idx=0)
      (f_66): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_43): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_35): Embedding(3, 64, padding_idx=0)
      (f_49): Embedding(15, 64, padding_idx=0)
      (f_42): Embedding(6725, 64, padding_idx=0)
      (f_12): Embedding(25, 64, padding_idx=0)
      (f_26): Embedding(3, 64, padding_idx=0)
      (f_10): Embedding(4, 64, padding_idx=0)
      (f_59): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_2): Embedding(136, 64, padding_idx=0)
      (f_67): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_23): Embedding(5, 64, padding_idx=0)
      (f_40): Embedding(3, 64, padding_idx=0)
      (f_15): Embedding(4277, 64, padding_idx=0)
      (f_30): Embedding(3, 64, padding_idx=0)
      (f_24): Embedding(5, 64, padding_idx=0)
      (f_36): Embedding(3, 64, padding_idx=0)
      (f_58): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_69): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_76): Embedding(9, 64, padding_idx=0)
      (f_56): Embedding(182, 64, padding_idx=0)
      (f_77): Embedding(5, 64, padding_idx=0)
      (f_65): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_4): Embedding(631, 64, padding_idx=0)
      (f_3): Embedding(6, 64, padding_idx=0)
      (f_48): Embedding(21, 64, padding_idx=0)
      (f_51): Embedding(1725, 64, padding_idx=0)
      (f_25): Embedding(4, 64, padding_idx=0)
      (f_17): Embedding(42, 64, padding_idx=0)
      (f_50): Embedding(22, 64, padding_idx=0)
      (f_70): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_33): Embedding(3, 64, padding_idx=0)
      (f_9): Embedding(8, 64, padding_idx=0)
      (f_61): Embedding(584, 64, padding_idx=0)
      (f_78): Embedding(11, 64, padding_idx=0)
      (f_45): Embedding(19, 64, padding_idx=0)
      (f_5): Embedding(7, 64, padding_idx=0)
      (f_19): Embedding(20, 64, padding_idx=0)
      (f_75): Embedding(32, 64, padding_idx=0)
      (f_39): Embedding(3, 64, padding_idx=0)
      (f_60): Embedding(232, 64, padding_idx=0)
      (f_72): Embedding(12, 64, padding_idx=0)
      (f_71): Embedding(5, 64, padding_idx=0)
      (f_31): Embedding(3, 64, padding_idx=0)
      (f_64): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_37): Embedding(3, 64, padding_idx=0)
      (f_21): Embedding(35, 64, padding_idx=0)
      (f_20): Embedding(56, 64, padding_idx=0)
      (f_34): Embedding(3, 64, padding_idx=0)
      (f_32): Embedding(5, 64, padding_idx=0)
      (f_11): Embedding(25, 64, padding_idx=0)
      (f_1): DenseEmbedding(
        embedding_dim=64, bias=False, batch_norm=True
        (batch_norm_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (weight): Linear(in_features=1, out_features=64, bias=False)
      )
      (f_16): Embedding(11, 64, padding_idx=0)
      (f_62): Embedding(1032, 64, padding_idx=0)
      (f_74): Embedding(5, 64, padding_idx=0)
      (f_63): Embedding(298, 64, padding_idx=0)
      (f_8): Embedding(7, 64, padding_idx=0)
      (f_79): Embedding(7, 64, padding_idx=0)
      (f_6): Embedding(4455, 64, padding_idx=0)
      (f_18): Embedding(543, 64, padding_idx=0)
      (f_22): Embedding(25, 64, padding_idx=0)
      (f_46): Embedding(11, 64, padding_idx=0)
      (f_44): Embedding(18, 64, padding_idx=0)
      (f_53): Embedding(85, 64, padding_idx=0)
    )
  )
  (experts): ModuleList(
    (0-3): 4 x MLPModule(
      (model): Sequential(
        (0): Dropout(p=0.1, inplace=False)
        (1): Linear(in_features=4800, out_features=128, bias=True)
        (2): ReLU()
        (3): Dropout(p=0.1, inplace=False)
        (4): Linear(in_features=128, out_features=128, bias=True)
        (5): ReLU()
      )
    )
  )
  (gates): ModuleDict(
    (is_clicked): MLPModule(
      (model): Sequential(
        (0): Dropout(p=0.1, inplace=False)
        (1): Linear(in_features=4800, out_features=128, bias=True)
        (2): ReLU()
        (3): Dropout(p=0.1, inplace=False)
        (4): Linear(in_features=128, out_features=4, bias=True)
        (5): ReLU()
        (6): Softmax(dim=-1)
      )
    )
    (is_installed): MLPModule(
      (model): Sequential(
        (0): Dropout(p=0.1, inplace=False)
        (1): Linear(in_features=4800, out_features=128, bias=True)
        (2): ReLU()
        (3): Dropout(p=0.1, inplace=False)
        (4): Linear(in_features=128, out_features=4, bias=True)
        (5): ReLU()
        (6): Softmax(dim=-1)
      )
    )
  )
  (towers): ModuleDict(
    (is_clicked): MLPModule(
      (model): Sequential(
        (0): Dropout(p=0.1, inplace=False)
        (1): Linear(in_features=128, out_features=128, bias=True)
        (2): ReLU()
        (3): Dropout(p=0.1, inplace=False)
        (4): Linear(in_features=128, out_features=1, bias=True)
      )
    )
    (is_installed): MLPModule(
      (model): Sequential(
        (0): Dropout(p=0.1, inplace=False)
        (1): Linear(in_features=128, out_features=128, bias=True)
        (2): ReLU()
        (3): Dropout(p=0.1, inplace=False)
        (4): Linear(in_features=128, out_features=1, bias=True)
      )
    )
  )
)
[2023-06-18 21:45:54] INFO GPU id [0] are selected.
[2023-06-18 21:47:07] INFO Training: Epoch=  0 [train_loss_0=0.2867 is_clicked logloss=0.4516 accuracy=0.8050 f1=0.6562 precision=0.9165 recall=0.5111 auc=0.8178 train_loss_0=0.2957 is_installed logloss=0.3780 accuracy=0.8244 f1=0.2196 precision=0.6757 recall=0.1314 auc=0.8332 train_loss_0=0.2818]
[2023-06-18 21:47:07] INFO Train time: 60.47213s. Valid time: 0.26492s. GPU RAM: 0.32/10.76 GB
[2023-06-18 21:47:07] INFO logloss improved. Best value: 0.3780
[2023-06-18 21:48:00] INFO Training: Epoch=  1 [train_loss_0=0.2719 is_clicked logloss=0.4813 accuracy=0.7941 f1=0.6513 precision=0.8489 recall=0.5284 auc=0.7875 train_loss_0=0.2805 is_installed logloss=0.3810 accuracy=0.8243 f1=0.2782 precision=0.6161 recall=0.1799 auc=0.8180 train_loss_0=0.2672]
[2023-06-18 21:48:00] INFO Train time: 53.43265s. Valid time: 0.14186s. GPU RAM: 0.32/10.76 GB
[2023-06-18 21:48:54] INFO Training: Epoch=  2 [train_loss_0=0.2674 is_clicked logloss=0.5344 accuracy=0.7687 f1=0.6164 precision=0.7777 recall=0.5107 auc=0.7693 train_loss_0=0.2756 is_installed logloss=0.3923 accuracy=0.8208 f1=0.2531 precision=0.5919 recall=0.1612 auc=0.8174 train_loss_0=0.2630]
[2023-06-18 21:48:54] INFO Train time: 53.99536s. Valid time: 0.12522s. GPU RAM: 0.32/10.76 GB
[2023-06-18 21:49:49] INFO Training: Epoch=  3 [train_loss_0=0.2637 is_clicked logloss=0.4940 accuracy=0.7772 f1=0.6301 precision=0.7963 recall=0.5215 auc=0.7842 train_loss_0=0.2714 is_installed logloss=0.3912 accuracy=0.8224 f1=0.2455 precision=0.6164 recall=0.1535 auc=0.8083 train_loss_0=0.2594]
[2023-06-18 21:49:49] INFO Train time: 54.01491s. Valid time: 0.12205s. GPU RAM: 0.32/10.76 GB
[2023-06-18 21:50:43] INFO Training: Epoch=  4 [train_loss_0=0.2609 is_clicked logloss=0.5020 accuracy=0.7747 f1=0.6268 precision=0.7893 recall=0.5200 auc=0.7732 train_loss_0=0.2686 is_installed logloss=0.3915 accuracy=0.8228 f1=0.2473 precision=0.6200 recall=0.1546 auc=0.8085 train_loss_0=0.2567]
[2023-06-18 21:50:43] INFO Train time: 54.11055s. Valid time: 0.12081s. GPU RAM: 0.32/10.76 GB
[2023-06-18 21:51:37] INFO Training: Epoch=  5 [train_loss_0=0.2590 is_clicked logloss=0.4963 accuracy=0.7891 f1=0.6387 precision=0.8485 recall=0.5122 auc=0.7876 train_loss_0=0.2665 is_installed logloss=0.3857 accuracy=0.8228 f1=0.2665 precision=0.6083 recall=0.1709 auc=0.8130 train_loss_0=0.2549]
[2023-06-18 21:51:37] INFO Train time: 53.90337s. Valid time: 0.12258s. GPU RAM: 0.32/10.76 GB
[2023-06-18 21:52:31] INFO Training: Epoch=  6 [train_loss_0=0.2572 is_clicked logloss=0.5063 accuracy=0.7794 f1=0.6314 precision=0.8058 recall=0.5191 auc=0.7932 train_loss_0=0.2650 is_installed logloss=0.3853 accuracy=0.8237 f1=0.2764 precision=0.6121 recall=0.1788 auc=0.8198 train_loss_0=0.2529]
[2023-06-18 21:52:31] INFO Train time: 53.81780s. Valid time: 0.12388s. GPU RAM: 0.32/10.76 GB
[2023-06-18 21:53:25] INFO Training: Epoch=  7 [train_loss_0=0.2554 is_clicked logloss=0.4951 accuracy=0.7881 f1=0.6473 precision=0.8211 recall=0.5343 auc=0.7881 train_loss_0=0.2637 is_installed logloss=0.3828 accuracy=0.8247 f1=0.2912 precision=0.6140 recall=0.1912 auc=0.8189 train_loss_0=0.2509]
[2023-06-18 21:53:25] INFO Train time: 53.72471s. Valid time: 0.12411s. GPU RAM: 0.32/10.76 GB
[2023-06-18 21:54:19] INFO Training: Epoch=  8 [train_loss_0=0.2540 is_clicked logloss=0.4905 accuracy=0.7925 f1=0.6423 precision=0.8622 recall=0.5119 auc=0.8040 train_loss_0=0.2625 is_installed logloss=0.4007 accuracy=0.8223 f1=0.2221 precision=0.6356 recall=0.1348 auc=0.8129 train_loss_0=0.2493]
[2023-06-18 21:54:19] INFO Train time: 53.85201s. Valid time: 0.12122s. GPU RAM: 0.33/10.76 GB
[2023-06-18 21:55:13] INFO Training: Epoch=  9 [train_loss_0=0.2525 is_clicked logloss=0.4894 accuracy=0.7825 f1=0.6408 precision=0.8034 recall=0.5330 auc=0.7863 train_loss_0=0.2613 is_installed logloss=0.3867 accuracy=0.8235 f1=0.2339 precision=0.6445 recall=0.1430 auc=0.8142 train_loss_0=0.2477]
[2023-06-18 21:55:13] INFO Train time: 53.79444s. Valid time: 0.12372s. GPU RAM: 0.33/10.76 GB
[2023-06-18 21:56:07] INFO Training: Epoch= 10 [train_loss_0=0.2510 is_clicked logloss=0.4826 accuracy=0.7894 f1=0.6513 precision=0.8197 recall=0.5404 auc=0.7995 train_loss_0=0.2602 is_installed logloss=0.3861 accuracy=0.8195 f1=0.3269 precision=0.5503 recall=0.2327 auc=0.8103 train_loss_0=0.2460]
[2023-06-18 21:56:07] INFO Train time: 53.92261s. Valid time: 0.12441s. GPU RAM: 0.33/10.76 GB
[2023-06-18 21:56:07] INFO Early stopped. Since the metric logloss haven't been improved for 10 epochs.
[2023-06-18 21:56:07] INFO The best score of logloss is 0.3780 on epoch 0
[2023-06-18 21:56:07] INFO Best model checkpoint saved in ./saved/MMoE/recsys/2023-06-18-21-44-41.ckpt.
