{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn.metrics as M\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_metrics = {\n",
    "    'precision': M.precision_score,\n",
    "    'auc': M.roc_auc_score,\n",
    "    'accuracy': M.accuracy_score,\n",
    "    'recall': M.recall_score,\n",
    "    'f1_score': M.f1_score,\n",
    "    'logloss': M.log_loss,\n",
    "    'mse': M.mean_squared_error,\n",
    "    'mae': M.mean_absolute_error\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'click'\n",
    "data_pth = f'/root/data/xingmei/Sharechat-RecSys-Challenge-23/data/{task}_trn_val.csv'\n",
    "df = pd.read_csv(data_pth, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>...</th>\n",
       "      <th>f_71</th>\n",
       "      <th>f_72</th>\n",
       "      <th>f_73</th>\n",
       "      <th>f_74</th>\n",
       "      <th>f_75</th>\n",
       "      <th>f_76</th>\n",
       "      <th>f_77</th>\n",
       "      <th>f_78</th>\n",
       "      <th>f_79</th>\n",
       "      <th>is_clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2697944</th>\n",
       "      <td>55</td>\n",
       "      <td>20095</td>\n",
       "      <td>563</td>\n",
       "      <td>31686</td>\n",
       "      <td>25604</td>\n",
       "      <td>590</td>\n",
       "      <td>27941</td>\n",
       "      <td>19203</td>\n",
       "      <td>23218</td>\n",
       "      <td>19343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.284486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021894</th>\n",
       "      <td>63</td>\n",
       "      <td>25976</td>\n",
       "      <td>22294</td>\n",
       "      <td>7696</td>\n",
       "      <td>21545</td>\n",
       "      <td>17507</td>\n",
       "      <td>27941</td>\n",
       "      <td>21218</td>\n",
       "      <td>869</td>\n",
       "      <td>19343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571121</td>\n",
       "      <td>0.571121</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59880</th>\n",
       "      <td>48</td>\n",
       "      <td>20095</td>\n",
       "      <td>563</td>\n",
       "      <td>31686</td>\n",
       "      <td>21545</td>\n",
       "      <td>590</td>\n",
       "      <td>27941</td>\n",
       "      <td>21218</td>\n",
       "      <td>23218</td>\n",
       "      <td>22970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325899</th>\n",
       "      <td>58</td>\n",
       "      <td>26325</td>\n",
       "      <td>22294</td>\n",
       "      <td>4896</td>\n",
       "      <td>19072</td>\n",
       "      <td>26293</td>\n",
       "      <td>27941</td>\n",
       "      <td>21218</td>\n",
       "      <td>31372</td>\n",
       "      <td>19343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571121</td>\n",
       "      <td>0.571121</td>\n",
       "      <td>0.077128</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581078</th>\n",
       "      <td>56</td>\n",
       "      <td>11077</td>\n",
       "      <td>7152</td>\n",
       "      <td>18575</td>\n",
       "      <td>21545</td>\n",
       "      <td>20137</td>\n",
       "      <td>27941</td>\n",
       "      <td>21621</td>\n",
       "      <td>869</td>\n",
       "      <td>19343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f_1    f_2    f_3    f_4    f_5    f_6    f_7    f_8    f_9   f_10  \\\n",
       "2697944   55  20095    563  31686  25604    590  27941  19203  23218  19343   \n",
       "2021894   63  25976  22294   7696  21545  17507  27941  21218    869  19343   \n",
       "59880     48  20095    563  31686  21545    590  27941  21218  23218  22970   \n",
       "2325899   58  26325  22294   4896  19072  26293  27941  21218  31372  19343   \n",
       "2581078   56  11077   7152  18575  21545  20137  27941  21621    869  19343   \n",
       "\n",
       "         ...  f_71      f_72      f_73      f_74      f_75      f_76  f_77  \\\n",
       "2697944  ...   0.0  2.284486  0.000000  0.115692  1.156922  0.269948   0.0   \n",
       "2021894  ...   0.0  0.571121  0.571121  0.115692  1.156922  0.269948   0.0   \n",
       "59880    ...   0.0  0.000000  0.000000  0.115692  1.156922  0.269948   0.0   \n",
       "2325899  ...   0.0  0.571121  0.571121  0.077128  1.156922  0.269948   0.0   \n",
       "2581078  ...   0.0  0.000000  0.000000  0.115692  1.156922  0.269948   0.0   \n",
       "\n",
       "         f_78  f_79  is_clicked  \n",
       "2697944   0.0   0.0           0  \n",
       "2021894   0.0   0.0           0  \n",
       "59880     0.0   0.0           0  \n",
       "2325899   0.0   0.0           0  \n",
       "2581078   0.0   0.0           0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['f_30', 'f_31']:\n",
    "    df[i] = df[i].fillna(df[i].mode().iloc[0])\n",
    "for i in ['f_43', 'f_51', 'f_58', 'f_59', 'f_64', 'f_65', 'f_66', 'f_67', 'f_68', 'f_69', 'f_70']:\n",
    "    df[i] = df[i].fillna(df[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.iloc[:1016364, :-1].to_numpy()\n",
    "y_train = df.iloc[:1016364, -1].to_numpy()\n",
    "X_test = df.iloc[1016364:, :-1].to_numpy()\n",
    "y_test = df.iloc[1016364:, -1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2216078798520179"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\n",
    "    # LogisticRegression(random_state=2023, multi_class='ovr'),\n",
    "    # MLPClassifier(max_iter=100, early_stopping=True, random_state=2022, hidden_layer_sizes=(20,20,20)),\n",
    "    # KNeighborsClassifier(n_neighbors=3),\n",
    "    # CategoricalNB(),\n",
    "    GaussianNB(),                               # All as continuous features\n",
    "    DecisionTreeClassifier(random_state=2023),  # All as continuous features\n",
    "    XGBClassifier(n_estimators=100, max_depth=5, learning=0.1, silent=False, objective='binary:logitraw')\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make use of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.naive_bayes.GaussianNB'>\n",
      "'precision': 0.26, 'auc': 0.6, 'accuracy': 0.78, 'recall': 0.01, 'f1_score': 0.01, 'logloss': 8.08, 'mse': 0.22, 'mae': 0.22\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "'precision': 0.51, 'auc': 0.7, 'accuracy': 0.78, 'recall': 0.55, 'f1_score': 0.53, 'logloss': 7.83, 'mse': 0.22, 'mae': 0.22\n",
      "[11:36:46] WARNING: /croot/xgboost-split_1675457761144/work/src/learner.cc:767: \n",
      "Parameters: { \"learning\", \"silent\" } are not used.\n",
      "\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "'precision': 0.94, 'auc': 0.85, 'accuracy': 0.87, 'recall': 0.44, 'f1_score': 0.6, 'logloss': 4.73, 'mse': 0.13, 'mae': 0.13\n"
     ]
    }
   ],
   "source": [
    "for model in MODELS:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat_prob = model.predict_proba(np.array(X_test))[:, 1]\n",
    "    y_pred = model.predict(np.array(X_test))\n",
    "    results = {}\n",
    "    for k, f in pred_metrics.items():\n",
    "        if k != 'auc':\n",
    "            results[k] = round(f(y_test, y_pred), 2)\n",
    "        else:\n",
    "            results[k] = round(f(y_test, y_hat_prob), 2)\n",
    "    print(str(type(model)) + '\\n' + str(results).strip('{}'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make use of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only use categorical features\n",
      "<class 'sklearn.naive_bayes.GaussianNB'>\n",
      "'precision': 1.0, 'auc': 0.64, 'accuracy': 0.78, 'recall': 0.0, 'f1_score': 0.0, 'logloss': 7.98, 'mse': 0.22, 'mae': 0.22\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "'precision': 0.51, 'auc': 0.7, 'accuracy': 0.78, 'recall': 0.56, 'f1_score': 0.53, 'logloss': 7.86, 'mse': 0.22, 'mae': 0.22\n",
      "[11:48:16] WARNING: /croot/xgboost-split_1675457761144/work/src/learner.cc:767: \n",
      "Parameters: { \"learning\", \"silent\" } are not used.\n",
      "\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "'precision': 0.94, 'auc': 0.85, 'accuracy': 0.87, 'recall': 0.44, 'f1_score': 0.6, 'logloss': 4.72, 'mse': 0.13, 'mae': 0.13\n"
     ]
    }
   ],
   "source": [
    "cat_X_train = X_train[:, :41]   # Date(f_1), Categorical features(f_2 to f_32), Binary features(f_33 to f_41)\n",
    "cat_X_test = X_test[:, :41]\n",
    "\n",
    "print('Only use categorical features')\n",
    "for model in MODELS:\n",
    "    model.fit(cat_X_train, y_train)\n",
    "    y_hat_prob = model.predict_proba(np.array(cat_X_test))[:, 1]\n",
    "    y_pred = model.predict(np.array(cat_X_test))\n",
    "    results = {}\n",
    "    for k, f in pred_metrics.items():\n",
    "        if k != 'auc':\n",
    "            results[k] = round(f(y_test, y_pred), 2)\n",
    "        else:\n",
    "            results[k] = round(f(y_test, y_hat_prob), 2)\n",
    "    print(str(type(model)) + '\\n' + str(results).strip('{}'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make use of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only use numerical features\n",
      "<class 'sklearn.naive_bayes.GaussianNB'>\n",
      "'precision': 0.26, 'auc': 0.58, 'accuracy': 0.78, 'recall': 0.01, 'f1_score': 0.01, 'logloss': 8.08, 'mse': 0.22, 'mae': 0.22\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "'precision': 0.44, 'auc': 0.64, 'accuracy': 0.75, 'recall': 0.45, 'f1_score': 0.45, 'logloss': 8.98, 'mse': 0.25, 'mae': 0.25\n",
      "[11:53:56] WARNING: /croot/xgboost-split_1675457761144/work/src/learner.cc:767: \n",
      "Parameters: { \"learning\", \"silent\" } are not used.\n",
      "\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "'precision': 0.91, 'auc': 0.8, 'accuracy': 0.83, 'recall': 0.28, 'f1_score': 0.43, 'logloss': 5.97, 'mse': 0.17, 'mae': 0.17\n"
     ]
    }
   ],
   "source": [
    "con_X_train = X_train[:, 41:]   # Numerical features(f_42 to f_79)\n",
    "con_X_test = X_test[:, 41:]\n",
    "\n",
    "print('Only use numerical features')\n",
    "for model in MODELS:\n",
    "    model.fit(con_X_train, y_train)\n",
    "    y_hat_prob = model.predict_proba(np.array(con_X_test))[:, 1]\n",
    "    y_pred = model.predict(np.array(con_X_test))\n",
    "    results = {}\n",
    "    for k, f in pred_metrics.items():\n",
    "        if k != 'auc':\n",
    "            results[k] = round(f(y_test, y_pred), 2)\n",
    "        else:\n",
    "            results[k] = round(f(y_test, y_hat_prob), 2)\n",
    "    print(str(type(model)) + '\\n' + str(results).strip('{}'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Methods for Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only use categorical features\n",
      "<class 'sklearn.naive_bayes.BernoulliNB'>\n",
      "'precision': 0.45, 'accuracy': 0.78, 'recall': 0.02, 'f1_score': 0.04, 'logloss': 8.03, 'mse': 0.22, 'mae': 0.22\n",
      "<class 'sklearn.naive_bayes.CategoricalNB'>\n",
      "'precision': 0.74, 'accuracy': 0.81, 'recall': 0.2, 'f1_score': 0.32, 'logloss': 6.95, 'mse': 0.19, 'mae': 0.19\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "BAYES_MODELS = [\n",
    "    BernoulliNB(),\n",
    "    CategoricalNB()\n",
    "]\n",
    "cat_X_train = X_train[:, :41]   # Date(f_1), Categorical features(f_2 to f_32), Binary features(f_33 to f_41)\n",
    "cat_X_test = X_test[:, :41]\n",
    "for i, col in zip(range(cat_X_test.shape[1]), df.columns):\n",
    "    tst_ooc = not set(np.unique(cat_X_test[:, i])).issubset(set(np.unique(cat_X_train[:, i])))\n",
    "    if tst_ooc:\n",
    "        cat_X_train[:, i] = 0\n",
    "        cat_X_test[:, i] = 0\n",
    "\n",
    "print('Only use categorical features')\n",
    "for model in BAYES_MODELS:\n",
    "    model.fit(cat_X_train, y_train)\n",
    "    # y_hat_prob = model.predict_proba(np.array(cat_X_test))[:, 1]\n",
    "    y_pred = model.predict(np.array(cat_X_test))\n",
    "    results = {}\n",
    "    for k, f in pred_metrics.items():\n",
    "        if k != 'auc':\n",
    "            results[k] = round(f(y_test, y_pred), 2)\n",
    "        else:\n",
    "            pass\n",
    "            # results[k] = round(f(y_test, y_hat_prob), 2)\n",
    "    print(str(type(model)) + '\\n' + str(results).strip('{}'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
